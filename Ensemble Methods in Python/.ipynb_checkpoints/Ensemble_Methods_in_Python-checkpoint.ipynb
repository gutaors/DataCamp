{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Narrando o aprendizado\n",
    "Este caderno começa como todos os outros, com os imports mais básicos e jogando o matplotlib pra inline\n",
    "importa o csv, \n",
    "    qual a biblioteca do comando que lê csv?\n",
    "    qual o comando?\n",
    "    qual a sintaxe para passar o nome do arquivo?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "#source = inspect.getsource(function)\n",
    "#print(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Multiple Models\n",
    "\n",
    "Como ele combina? \n",
    "Qual o passo a passo? \n",
    "Tem pré processamento?\n",
    "tente escrever a célula e confira com a do cara para validar, lembre de no começo escrever #MinhaCélula\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pd.read_csv('googleplaystore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Category</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Size</th>\n",
       "      <th>Installs</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Content Rating</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Last Updated</th>\n",
       "      <th>Current Ver</th>\n",
       "      <th>Android Ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Photo Editor &amp; Candy Camera &amp; Grid &amp; ScrapBook</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>159</td>\n",
       "      <td>19M</td>\n",
       "      <td>10,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>January 7, 2018</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coloring book moana</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>967</td>\n",
       "      <td>14M</td>\n",
       "      <td>500,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design;Pretend Play</td>\n",
       "      <td>January 15, 2018</td>\n",
       "      <td>2.0.0</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U Launcher Lite – FREE Live Cool Themes, Hide ...</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>87510</td>\n",
       "      <td>8.7M</td>\n",
       "      <td>5,000,000+</td>\n",
       "      <td>Free</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>Art &amp; Design</td>\n",
       "      <td>August 1, 2018</td>\n",
       "      <td>1.2.4</td>\n",
       "      <td>4.0.3 and up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 App        Category  Rating  \\\n",
       "0     Photo Editor & Candy Camera & Grid & ScrapBook  ART_AND_DESIGN     4.1   \n",
       "1                                Coloring book moana  ART_AND_DESIGN     3.9   \n",
       "2  U Launcher Lite – FREE Live Cool Themes, Hide ...  ART_AND_DESIGN     4.7   \n",
       "\n",
       "  Reviews  Size    Installs  Type Price Content Rating  \\\n",
       "0     159   19M     10,000+  Free     0       Everyone   \n",
       "1     967   14M    500,000+  Free     0       Everyone   \n",
       "2   87510  8.7M  5,000,000+  Free     0       Everyone   \n",
       "\n",
       "                      Genres      Last Updated Current Ver   Android Ver  \n",
       "0               Art & Design   January 7, 2018       1.0.0  4.0.3 and up  \n",
       "1  Art & Design;Pretend Play  January 15, 2018       2.0.0  4.0.3 and up  \n",
       "2               Art & Design    August 1, 2018       1.2.4  4.0.3 and up  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #MinhaCélula\n",
    "app.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comando para mostrar quantidade de null por variável, dica do Christian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "App                  0\n",
       "Category             0\n",
       "Rating            1474\n",
       "Reviews              0\n",
       "Size                 0\n",
       "Installs             0\n",
       "Type                 1\n",
       "Price                0\n",
       "Content Rating       1\n",
       "Genres               0\n",
       "Last Updated         0\n",
       "Current Ver          8\n",
       "Android Ver          3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aqui o malaco fez o seguinte, pegou o type que falava se era gratuito ou não e transformou no tipo Paid que tem 0 ou 1\n",
    "É interessante notar que o get_dummies é um tipo do pandas e ele já tem este tipo Paid, tentei mudar para Pagou e deu erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(app['Type'])\n",
    "app = app.drop('Type', axis = 1)\n",
    "app = pd.concat([app, dummy['Paid']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### abaixo ele faz diferente, troca a palavra Teen por 10 e depois roda uma expressão que transforma o campo Content Rating em números, bota num float e arredonda o float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "app['Content Rating'] = app['Content Rating'].replace('Teen', '10')\n",
    "app['Content Rating'] = app['Content Rating'].str.extract(r'(\\d+)').astype(float)\n",
    "app['Content Rating'] = app['Content Rating'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### campo Size, converte em número também ver qual a lógica, já sei que quando o campo está preenchido com Varies whth device ele arranca fora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "app['Size'] = app['Size'].apply(lambda x: str(float(x.replace('k', '')) / 1000) if 'k' in x else x)\n",
    "app['Size'] = app['Size'].replace('Varies with device', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Várias operações aqui, lindo este código aqui\n",
    "price = trocou Everyone por 0\n",
    "\n",
    "trocou todos free por 0\n",
    "\n",
    "definiu alguns caracteres em uma lista\n",
    "\n",
    "\n",
    "definiu alguns nomes de colunas em outra lista\n",
    "\n",
    "fez um luoop percorrendo as colunas\n",
    "\n",
    "\n",
    "    dentro deste loop percorreu os caracteres\n",
    "    \n",
    "       para cada coluna destas no dataframe, trocou o char por ''\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "app['Price'] = app['Price'].replace('Everyone', '0')\n",
    "app = app.replace('Free', 0)\n",
    "chars = ['+', '$', 'M', ',']\n",
    "cols = ['Reviews','Size', 'Installs', 'Price']\n",
    "for col in cols:\n",
    "    for char in chars:\n",
    "        app[col] = app[col].str.replace(char, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mudou o tipo destas colunas que são as mesmas que acabou de tratar\n",
    "Em seguida rodou dropna para remover os null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "app[['Reviews', 'Size', 'Installs', 'Price']].astype(float)\n",
    "app = app.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separou as colunas X e y, lembrando que ao contrário da intuição, y é o alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = app[['Reviews', 'Size', 'Installs', 'Paid', 'Price', 'Content Rating']]\n",
    "y = app['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the rating of an app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separa em X e y, qual função que usa pra isto? esta função pertence a quem?\n",
    "Rodou um regressor de Árvore de Decisão, não é random forest, é um regressor porque estou tentando achar uma estimativa de  valor, na dúvida veja o print(y) acima para verificar o que vou encontrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=3,\n",
       "                      min_samples_split=9, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=500, splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Split into train (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "# Instantiate the regressor\n",
    "reg_dt = DecisionTreeRegressor(min_samples_leaf = 3, min_samples_split = 9, random_state=500)\n",
    "\n",
    "# Fit to the training set\n",
    "reg_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### aqui o esquema é outro, vamos abrir outro csv e fazer outras coisas divertidas\n",
    "#### parece que o bixinho já está bem preparado pois não tem pré processamento aqui. Já abre, separa colunas e mente bronca no split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name Type 1  Type 2  Total  HP  Attack  Defense  Sp. Atk  \\\n",
       "#                                                                              \n",
       "1              Bulbasaur  Grass  Poison    318  45      49       49       65   \n",
       "2                Ivysaur  Grass  Poison    405  60      62       63       80   \n",
       "3               Venusaur  Grass  Poison    525  80      82       83      100   \n",
       "3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123      122   \n",
       "4             Charmander   Fire     NaN    309  39      52       43       60   \n",
       "\n",
       "   Sp. Def  Speed  Generation  Legendary  \n",
       "#                                         \n",
       "1       65     45           1      False  \n",
       "2       80     60           1      False  \n",
       "3      100     80           1      False  \n",
       "3      120     80           1      False  \n",
       "4       50     65           1      False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkm = pd.read_csv('Pokemon.csv', index_col = 0)\n",
    "X = pkm[['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Generation']]\n",
    "y = pkm['Legendary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "pkm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pronto, agora começa a evoluir, vamos abrir uma porrada de biblioteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fez fit em três modelos, regressão logística, classificador árvore de decisão e Classificador KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression(solver = 'liblinear').fit(X_train, y_train)\n",
    "clf_dt = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "clf_knn = KNeighborsClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### avalia os modelos da seguinte forma\n",
    "cria uma variável pred para cada algoritmo\n",
    "Como? as predições eu vou jogar em uma variável pred_.. cada predict que fiz, passo o modelo que fiz fit ali em cima .predict(X_test) faço a previsão para o X_test\n",
    "\n",
    "avalio a qualidade verificando contra o y_test contra o pred que criei logo acima, jogo o resultado em uma lista score\n",
    "\n",
    "printo os scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4285714285714285\n",
      "0.47619047619047616\n",
      "0.47619047619047616\n"
     ]
    }
   ],
   "source": [
    "# Make the invidual predictions\n",
    "pred_lr = clf_lr.predict(X_test)\n",
    "pred_dt = clf_dt.predict(X_test)\n",
    "pred_knn = clf_knn.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of each model\n",
    "score_lr = f1_score(y_test, pred_lr)\n",
    "score_dt = f1_score(y_test, pred_dt)\n",
    "score_knn = f1_score(y_test, pred_knn)\n",
    "\n",
    "# Print the scores\n",
    "print(score_lr)\n",
    "print(score_dt)\n",
    "print(score_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling your first ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### montando seu primeiro conjunto\n",
    "instancia cada modelo\n",
    "\n",
    "no knn o parâmetro é número de vizinhos\n",
    "\n",
    "no LogisticRegression tem o solver que é linear\n",
    "\n",
    "e no Classificador Árvore de decisão tem leaf, split e random state\n",
    "\n",
    "dá um nome pra cada e depois faz um VotingClassifier que vai chamar os três gerando um X_train e yTrain, \n",
    "\n",
    "Lembra daquele lance de ver as questões que cada aluno resolve bem para colocá-los para resolver a prova? Está aí\n",
    "Que parãmetros passaos para o VotingClassifier? estimators =['abrev', nome_instancia]\n",
    "Faz vote.fit(X_treino e y_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn',\n",
       "                              KNeighborsClassifier(algorithm='auto',\n",
       "                                                   leaf_size=30,\n",
       "                                                   metric='minkowski',\n",
       "                                                   metric_params=None,\n",
       "                                                   n_jobs=None, n_neighbors=5,\n",
       "                                                   p=2, weights='uniform')),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2'...\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('dt',\n",
       "                              DecisionTreeClassifier(class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=3,\n",
       "                                                     min_samples_split=9,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     presort=False,\n",
       "                                                     random_state=500,\n",
       "                                                     splitter='best'))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the individual models\n",
    "clf_knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "clf_lr = LogisticRegression(class_weight = 'balanced', solver = 'liblinear')\n",
    "clf_dt = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "\n",
    "# Create and fit the voting classifier\n",
    "clf_vote = VotingClassifier(\n",
    "    estimators=[('knn', clf_knn), ('lr', clf_lr), ('dt', clf_dt)]\n",
    ")\n",
    "clf_vote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating your ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O modelo do Ensemble é tratado como um modelo qualquer, acima fizemos o fit nele, agora faremos o predict com X_test, \n",
    "\n",
    "depois faremos o score comparando pred_vote (nossas previsões) com o y_test e depois vamos fazer o print\n",
    "\n",
    "fazemos o report com o classification_report(y_test, pred_vote) ou seja, um relatório de classificação que compara o y (alvo) e o previsto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.95      0.97       150\n",
      "        True       0.50      0.70      0.58        10\n",
      "\n",
      "    accuracy                           0.94       160\n",
      "   macro avg       0.74      0.83      0.77       160\n",
      "weighted avg       0.95      0.94      0.94       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the predictions using the voting classifier\n",
    "pred_vote = clf_vote.predict(X_test)\n",
    "\n",
    "# Calculate the F1-Score of the voting classifier\n",
    "score_vote = f1_score(y_test, pred_vote)\n",
    "print('F1-Score: {:.3f}'.format(score_vote))\n",
    "\n",
    "# Calculate the classification report\n",
    "report = classification_report(y_test, pred_vote)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting GoT deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### leu o dataset, definiu quais features vão pro X, qual é o alvo (y)\n",
    "fez o split no dataset Game of Thrones, massa demais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>actual</th>\n",
       "      <th>pred</th>\n",
       "      <th>alive</th>\n",
       "      <th>plod</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>male</th>\n",
       "      <th>culture</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>...</th>\n",
       "      <th>isAliveHeir</th>\n",
       "      <th>isAliveSpouse</th>\n",
       "      <th>isMarried</th>\n",
       "      <th>isNoble</th>\n",
       "      <th>age</th>\n",
       "      <th>numDeadRelations</th>\n",
       "      <th>boolDeadRelations</th>\n",
       "      <th>isPopular</th>\n",
       "      <th>popularity</th>\n",
       "      <th>isAlive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.946</td>\n",
       "      <td>Viserys II Targaryen</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.605351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.613</td>\n",
       "      <td>Walder Frey</td>\n",
       "      <td>Lord of the Crossing</td>\n",
       "      <td>1</td>\n",
       "      <td>Rivermen</td>\n",
       "      <td>208.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.507</td>\n",
       "      <td>Addison Hill</td>\n",
       "      <td>Ser</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.924</td>\n",
       "      <td>Aemma Arryn</td>\n",
       "      <td>Queen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.383</td>\n",
       "      <td>Sylva Santagar</td>\n",
       "      <td>Greenstone</td>\n",
       "      <td>0</td>\n",
       "      <td>Dornish</td>\n",
       "      <td>276.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No  actual  pred  alive   plod                  name  \\\n",
       "0     1       0     0  0.054  0.946  Viserys II Targaryen   \n",
       "1     2       1     0  0.387  0.613           Walder Frey   \n",
       "2     3       1     0  0.493  0.507          Addison Hill   \n",
       "3     4       0     0  0.076  0.924           Aemma Arryn   \n",
       "4     5       1     1  0.617  0.383        Sylva Santagar   \n",
       "\n",
       "                  title  male   culture  dateOfBirth  ...  isAliveHeir  \\\n",
       "0                     0     1         0          0.0  ...          0.0   \n",
       "1  Lord of the Crossing     1  Rivermen        208.0  ...          0.0   \n",
       "2                   Ser     1         0          0.0  ...          0.0   \n",
       "3                 Queen     0         0         82.0  ...          0.0   \n",
       "4            Greenstone     0   Dornish        276.0  ...          0.0   \n",
       "\n",
       "  isAliveSpouse isMarried isNoble   age numDeadRelations  boolDeadRelations  \\\n",
       "0           0.0         0       0   0.0               11                  1   \n",
       "1           1.0         1       1  97.0                1                  1   \n",
       "2           0.0         0       1   0.0                0                  0   \n",
       "3           0.0         1       1  23.0                0                  0   \n",
       "4           1.0         1       1  29.0                0                  0   \n",
       "\n",
       "   isPopular  popularity  isAlive  \n",
       "0          1    0.605351        0  \n",
       "1          1    0.896321        1  \n",
       "2          0    0.267559        1  \n",
       "3          0    0.183946        0  \n",
       "4          0    0.043478        1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got = pd.read_csv('character-predictions.csv').fillna(0)\n",
    "X = got[['male', 'book1', 'book2', 'book3', 'book4', 'book5', 'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse', 'isMarried', 'isNoble', 'age', 'numDeadRelations', 'boolDeadRelations','isPopular', 'popularity']]\n",
    "y = got['isAlive']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "got.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faz um modelo de cada coisa, LogisticRegression, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Build the individual models\n",
    "clf_lr = LogisticRegression(class_weight='balanced', solver = 'liblinear')\n",
    "clf_dt = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "clf_svm = SVC(probability=True, class_weight='balanced', random_state=500, gamma = 'auto')\n",
    "\n",
    "# List of (string, estimator) tuples\n",
    "estimators = [('lr', clf_lr), ('dt', clf_dt), ('svm', clf_svm)]\n",
    "\n",
    "# Build and fit an averaging classifier\n",
    "clf_avg = VotingClassifier(estimators, voting='soft')\n",
    "clf_avg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "acc_avg = accuracy_score(y_test,  clf_avg.predict(X_test))\n",
    "print('Accuracy: {:.2f}'.format(acc_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft vs. hard voting\n",
    "O que é soft vs hard sob o ponto de vista da implementação?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting: 0.78, Averaging: 0.77\n"
     ]
    }
   ],
   "source": [
    "# List of (string, estimator) tuples\n",
    "estimators = [('dt', clf_dt), ('lr', clf_lr), ('knn', clf_knn)]\n",
    "\n",
    "# Build and fit a voting classifier\n",
    "clf_vote = VotingClassifier(estimators = estimators)\n",
    "clf_vote.fit(X_train, y_train)\n",
    "\n",
    "# Build and fit an averaging classifier\n",
    "clf_avg = VotingClassifier(estimators = estimators, voting = 'soft')\n",
    "clf_avg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of both models\n",
    "acc_vote = accuracy_score(y_test, clf_vote.predict(X_test))\n",
    "acc_avg = accuracy_score(y_test,  clf_avg.predict(X_test))\n",
    "print('Voting: {:.2f}, Averaging: {:.2f}'.format(acc_vote, acc_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restricted and unrestricted decision trees\n",
    "O que são as árvores restritas e irrestritas sob o ponto de vista da implementação??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pkm[['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Generation']]\n",
    "y = pkm['Legendary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[143   7]\n",
      " [  3   7]]\n",
      "F1-Score: 0.583\n"
     ]
    }
   ],
   "source": [
    "# Build unrestricted decision tree\n",
    "clf = DecisionTreeClassifier(min_samples_leaf = 3, min_samples_split = 9, random_state = 500)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print('Confusion matrix:\\n', cm)\n",
    "\n",
    "# Print the F1 score\n",
    "score = f1_score(y_test, pred)\n",
    "print('F1-Score: {:.3f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[146   4]\n",
      " [  5   5]]\n",
      "F1-Score: 0.526\n"
     ]
    }
   ],
   "source": [
    "# Build restricted decision tree\n",
    "clf = DecisionTreeClassifier(max_depth = 4, max_features=2, random_state=500)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print('Confusion matrix:\\n', cm)\n",
    "\n",
    "# Print the F1 score\n",
    "score = f1_score(y_test, pred)\n",
    "print('F1-Score: {:.3f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with bootstrapping\n",
    "Como treina com bootstrapping? que bagaça é esta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkm_sample = pkm.sample(640, replace = True)\n",
    "X = pkm_sample[['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Generation']]\n",
    "y = pkm_sample['Legendary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "                       max_features=2, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=500, splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a sample with replacement\n",
    "# X_train_sample = X_train.sample(frac = 1.0, replace = True, random_state=42)\n",
    "# y_train_sample = y_train.loc[X_train_sample.index]\n",
    "\n",
    "\n",
    "# Build a \"weak\" Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth = 4, max_features = 2, random_state=500)\n",
    "\n",
    "# Fit the model to the training sample\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging: the scikit-learn way\n",
    "Lembra do bagging? Qual(is) o(s) comando(s)?\n",
    "\n",
    "\n",
    "\n",
    "BAGGING ou BOOTSTRAP AGGREGATION\n",
    "Arvores profundas tendem a Overfitar e levam a mais variancia\n",
    "na random forest o treino é dividido em amostras aleatorias com reposição, gerando pequenos subsets. chamados de bootstrap samples\n",
    "Estes bootstraps são servidos para alimentar árvores de grande profundidade.\n",
    "cada árvore destas é treinada separadamente nestas amostras (bootstrap)\n",
    "Esta agregação de árvores é chamado Random Forest Ensemble \n",
    "O resultado final é obtido pelo voto da maioria, isto é chamado de Bagging ou Bootstrap Aggregation.\n",
    "Como cada árvore pegou um set de dados como amostra de treino, os desvios no dataset de treino original não impacta o resultado final obtido pela agregação de DTs\n",
    "Bagging reduz a variância sem alterar o BIAS do ensemble.\n",
    "\n",
    "OOB Score (Out of the bag)\n",
    "Deixamos linhas fora do dataset de treino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.759\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "# Instantiate the base model\n",
    "clf_dt = DecisionTreeClassifier(max_depth = 4)\n",
    "\n",
    "# Build and train the Bagging classifier\n",
    "clf_bag = BaggingClassifier(\n",
    "  clf_dt,\n",
    "  21,\n",
    "  random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "pred = clf_bag.predict(X_test)\n",
    "\n",
    "# Show the F1-score\n",
    "print('F1-Score: {:.3f}'.format(f1_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the out-of-bag score\n",
    "OOB, lembra? não ? dá uma lida  na net e depois olha o código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB-Score: 0.938\n",
      "Accuracy: 0.969\n"
     ]
    }
   ],
   "source": [
    "# Build and train the bagging classifier\n",
    "clf_bag = BaggingClassifier(\n",
    "  base_estimator=clf_dt,\n",
    "  n_estimators=21,\n",
    "  oob_score=True,\n",
    "  random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Print the out-of-bag score\n",
    "print('OOB-Score: {:.3f}'.format(clf_bag.oob_score_))\n",
    "\n",
    "# Evaluate the performance on the test set to compare\n",
    "pred = clf_bag.predict(X_test)\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more complex bagging model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci = pd.read_csv('uci-secom.csv', index_col = 'Time').fillna(0)\n",
    "X = uci.iloc[:, :590]\n",
    "y = uci['Pass/Fail']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regressão logística balanceada, classificador bagging e OOB, depois matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.66\n",
      "OOB-Score: 0.59\n",
      "[[195  95]\n",
      " [ 12  12]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\94275793668\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py:611: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\94275793668\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py:616: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "# Build a balanced logistic regression\n",
    "clf_lr = LogisticRegression(class_weight = 'balanced', solver = 'liblinear')\n",
    "\n",
    "# Build and fit a bagging classifier\n",
    "clf_bag = BaggingClassifier(base_estimator = clf_lr, n_estimators = 10, oob_score = True, max_features = 10, random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy on the test set and show the out-of-bag score\n",
    "pred = clf_bag.predict(X_test)\n",
    "print('Accuracy:  {:.2f}'.format(accuracy_score(y_test, pred)))\n",
    "print('OOB-Score: {:.2f}'.format(clf_bag.oob_score_))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning bagging hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\94275793668\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.79      0.85       290\n",
      "           1       0.09      0.25      0.13        24\n",
      "\n",
      "    accuracy                           0.75       314\n",
      "   macro avg       0.51      0.52      0.49       314\n",
      "weighted avg       0.86      0.75      0.80       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a balanced logistic regression\n",
    "clf_base = LogisticRegression(class_weight='balanced', random_state=42, solver = 'liblinear')\n",
    "\n",
    "# Build and fit a bagging classifier with custom parameters\n",
    "clf_bag = BaggingClassifier(base_estimator = clf_base, n_estimators = 500, max_features= 10, max_samples = 0.65, bootstrap = False, random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Calculate predictions and evaluate the accuracy on the test set\n",
    "y_pred = clf_bag.predict(X_test)\n",
    "print('Accuracy:  {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting movie revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv('tmdb_5000_movies.csv')\n",
    "X = movie['budget']\n",
    "y = movie['revenue']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_train = scaler.fit_transform(X_train.values.reshape(-1, 1))\n",
    "X_test = scaler.transform(X_test.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 97137084.354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Build and fit linear regression model\n",
    "reg_lm = LinearRegression(normalize = True)\n",
    "reg_lm.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = reg_lm.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "print('RMSE: {:.3f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your first AdaBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv('tmdb_5000_movies.csv')\n",
    "X = movie[['budget', 'popularity']]\n",
    "y = movie['revenue']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 137546852.649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "# Instantiate a normalized linear regression model\n",
    "reg_lm = LinearRegression(normalize = True)\n",
    "\n",
    "# Build and fit an AdaBoost regressor\n",
    "reg_ada = AdaBoostRegressor(base_estimator = reg_lm,n_estimators = 12,  random_state=500)\n",
    "reg_ada.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = reg_ada.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "print('RMSE: {:.3f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-based AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 100202890.122\n"
     ]
    }
   ],
   "source": [
    "# Build and fit a tree-based AdaBoost regressor\n",
    "reg_ada = AdaBoostRegressor(n_estimators = 12, random_state=500)\n",
    "reg_ada.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = reg_ada.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "print('RMSE: {:.3f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the most of AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv('tmdb_5000_movies.csv').dropna()\n",
    "X = movie[['budget', 'popularity', 'runtime', 'vote_average','vote_count']]\n",
    "y = movie['revenue']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 120953271.685\n"
     ]
    }
   ],
   "source": [
    "# Build and fit an AdaBoost regressor\n",
    "reg_ada = AdaBoostRegressor(n_estimators = 100, learning_rate = 0.01, random_state=500)\n",
    "reg_ada.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = reg_ada.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "print('RMSE: {:.3f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis with GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.020\n",
      "[[6 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Build and fit a Gradient Boosting classifier\n",
    "clf_gbm = GradientBoostingClassifier(n_estimators = 5, learning_rate = 0.1, random_state=500)\n",
    "clf_gbm.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = clf_gbm.predict(X_test)\n",
    "\n",
    "# Evaluate the performance based on the accuracy\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print('Accuracy: {:.3f}'.format(acc))\n",
    "\n",
    "# Get and show the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie revenue prediction with CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import catboost as cb\n",
    "# # Build and fit a CatBoost regressor\n",
    "# reg_cat = cb.CatBoostRegressor(n_estimators = 5, learning_rate = 0.1, max_depth = 3, random_state=500)\n",
    "# reg_cat.fit(X_train, y_train)\n",
    "\n",
    "# # Calculate the predictions on the set set\n",
    "# pred = reg_cat.predict(X_test)\n",
    "\n",
    "# # Evaluate the performance using the RMSE\n",
    "# rmse_cat = np.sqrt(mean_squared_error(y_test, pred))\n",
    "# print('RMSE (CatBoost): {:.3f}'.format(rmse_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting contest: Light vs Extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# # Build and fit a XGBoost regressor\n",
    "# reg_xgb = xgb.XGBRegressor(max_depth = 3, learning_rate = 0.1, n_estimators = 100, random_state=500)\n",
    "# reg_xgb.fit(X_train, y_train)\n",
    "\n",
    "# # Build and fit a LightGBM regressor\n",
    "# reg_lgb = lgb.LGBMRegressor(max_depth = 3, learning_rate = 0.1, n_estimators = 100, seed=500)\n",
    "# reg_lgb.fit(X_train, y_train)\n",
    "\n",
    "# # Calculate the predictions and evaluate both regressors\n",
    "# pred_xgb = reg_xgb.predict(X_test)\n",
    "# rmse_xgb = np.sqrt(mean_squared_error(y_test, pred_xgb))\n",
    "# pred_lgb = reg_lgb.predict(X_test)\n",
    "# rmse_lgb = np.sqrt(mean_squared_error(y_test, pred_lgb))\n",
    "\n",
    "# print('Extreme: {:.3f}, Light: {:.3f}'.format(rmse_xgb, rmse_lgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting mushroom edibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr = pd.read_csv('mushrooms.csv')\n",
    "y = pd.get_dummies(mr['class'])['p']\n",
    "X = pd.get_dummies(mr.drop('class', axis = 1))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "mr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Instantiate a Naive Bayes classifier\n",
    "clf_nb = GaussianNB()\n",
    "\n",
    "# Fit the model to the training set\n",
    "clf_nb.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = clf_nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the accuracy score\n",
    "print(\"Accuracy: {:0.4f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbors for mushrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a 5-nearest neighbors classifier with 'ball_tree' algorithm\n",
    "clf_knn = KNeighborsClassifier(n_neighbors = 5, algorithm = 'ball_tree')\n",
    "\n",
    "# Fit the model to the training set\n",
    "clf_knn.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = clf_knn.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the accuracy score\n",
    "print(\"Accuracy: {:0.4f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying stacking to predict app ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 1.0000\n",
      "5-Nearest Neighbors: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Build and fit a Decision Tree classifier\n",
    "clf_dt = DecisionTreeClassifier(min_samples_leaf = 3, min_samples_split = 9, random_state=500)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "\n",
    "# Build and fit a 5-nearest neighbors classifier using the 'Ball-Tree' algorithm\n",
    "clf_knn = KNeighborsClassifier(n_neighbors = 5, algorithm = 'ball_tree')\n",
    "clf_knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance using the accuracy score\n",
    "print('Decision Tree: {:0.4f}'.format(accuracy_score(y_test, clf_dt.predict(X_test))))\n",
    "print('5-Nearest Neighbors: {:0.4f}'.format(accuracy_score(y_test, clf_knn.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first attempt with mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-298-abe729ec1443>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#conda install mlxtend --channel conda-forge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Instantiate the first-layer classifiers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf_dt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclf_knn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ball_tree'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "#conda install mlxtend --channel conda-forge\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "# Instantiate the first-layer classifiers\n",
    "clf_dt = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree')\n",
    "\n",
    "# Instantiate the second-layer meta classifier\n",
    "clf_meta = DecisionTreeClassifier(random_state=500)\n",
    "\n",
    "# Build the Stacking classifier\n",
    "clf_stack = StackingClassifier(classifiers=[clf_dt, clf_knn], meta_classifier=clf_meta, use_features_in_secondary=True)\n",
    "clf_stack.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the Stacking classifier\n",
    "pred_stack = clf_stack.predict(X_test)\n",
    "print(\"Accuracy: {:0.4f}\".format(accuracy_score(y_test, pred_stack)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mushrooms: a matter of life or death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERRO name 'StackingClassifier' is not defined, para corrigir\n",
    "#conda update conda\n",
    "#conda install scikit-learn=0.19\n",
    "\n",
    "# Create the first-layer models\n",
    "clf_knn = KNeighborsClassifier(n_neighbors = 5, algorithm = 'ball_tree')\n",
    "clf_dt = DecisionTreeClassifier(min_samples_leaf = 5, min_samples_split = 15, random_state=500)\n",
    "clf_nb = GaussianNB()\n",
    "\n",
    "# Create the second-layer model (meta-model)\n",
    "clf_lr = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "# Create and fit the stacked model\n",
    "clf_stack = StackingClassifier(classifiers = [clf_knn, clf_dt, clf_nb], meta_classifier = clf_lr)\n",
    "clf_stack.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the stacked model’s performance\n",
    "print(\"Accuracy: {:0.4f}\".format(accuracy_score(y_test, clf_stack.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to regression with stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = app[['Reviews', 'Size', 'Installs', 'Paid', 'Price', 'Content Rating']]\n",
    "y = app['Rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# Instantiate the 1st-layer regressors\n",
    "reg_dt = DecisionTreeRegressor(min_samples_leaf = 11, min_samples_split = 33, random_state=500)\n",
    "reg_lr = LinearRegression(normalize = True)\n",
    "reg_ridge = Ridge(random_state = 500)\n",
    "\n",
    "# Instantiate the 2nd-layer regressor\n",
    "reg_meta = LinearRegression()\n",
    "\n",
    "# Build the Stacking regressor\n",
    "reg_stack = StackingRegressor([reg_dt, reg_lr, reg_ridge], reg_meta)\n",
    "reg_stack.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance on the test set using the MAE metric\n",
    "pred = reg_stack.predict(X_test)\n",
    "print('MAE: {:.3f}'.format(mean_absolute_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
