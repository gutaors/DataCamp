{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134338</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KINDERGARTEN</td>\n",
       "      <td>50471.810</td>\n",
       "      <td>KINDERGARTEN</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206341</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>CONTRACTOR SERVICES</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RGN  GOB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNDESIGNATED</td>\n",
       "      <td>3477.860</td>\n",
       "      <td>BUILDING IMPROVEMENT SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUILDING IMPROVEMENT SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326408</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>Non PreK</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>Personal Services - Teachers</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEACHER</td>\n",
       "      <td>62237.130</td>\n",
       "      <td>Instruction - Regular</td>\n",
       "      <td>General Purpose School</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364634</th>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Substitute</td>\n",
       "      <td>Benefits</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>EMPLOYEE BENEFITS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNALLOC BUDGETS/SCHOOLS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>22.300</td>\n",
       "      <td>GENERAL MIDDLE/JUNIOR HIGH SCH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47683</th>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>TEACHER COVERAGE FOR TEACHER</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NON-PROJECT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>54.166</td>\n",
       "      <td>GENERAL HIGH SCHOOL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Function          Use          Sharing Reporting  \\\n",
       "134338     Teacher Compensation  Instruction  School Reported    School   \n",
       "206341                 NO_LABEL     NO_LABEL         NO_LABEL  NO_LABEL   \n",
       "326408     Teacher Compensation  Instruction  School Reported    School   \n",
       "364634  Substitute Compensation  Instruction  School Reported    School   \n",
       "47683   Substitute Compensation  Instruction  School Reported    School   \n",
       "\n",
       "       Student_Type Position_Type               Object_Type     Pre_K  \\\n",
       "134338     NO_LABEL       Teacher                  NO_LABEL  NO_LABEL   \n",
       "206341     NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "326408  Unspecified       Teacher  Base Salary/Compensation  Non PreK   \n",
       "364634  Unspecified    Substitute                  Benefits  NO_LABEL   \n",
       "47683   Unspecified       Teacher   Substitute Compensation  NO_LABEL   \n",
       "\n",
       "         Operating_Status            Object_Description  ...  \\\n",
       "134338  PreK-12 Operating                           NaN  ...   \n",
       "206341      Non-Operating           CONTRACTOR SERVICES  ...   \n",
       "326408  PreK-12 Operating  Personal Services - Teachers  ...   \n",
       "364634  PreK-12 Operating             EMPLOYEE BENEFITS  ...   \n",
       "47683   PreK-12 Operating  TEACHER COVERAGE FOR TEACHER  ...   \n",
       "\n",
       "       Sub_Object_Description Location_Description  FTE  \\\n",
       "134338                    NaN                  NaN  1.0   \n",
       "206341                    NaN                  NaN  NaN   \n",
       "326408                    NaN                  NaN  1.0   \n",
       "364634                    NaN                  NaN  NaN   \n",
       "47683                     NaN                  NaN  NaN   \n",
       "\n",
       "           Function_Description Facility_or_Department  \\\n",
       "134338                      NaN                    NaN   \n",
       "206341                 RGN  GOB                    NaN   \n",
       "326408                      NaN                    NaN   \n",
       "364634  UNALLOC BUDGETS/SCHOOLS                    NaN   \n",
       "47683               NON-PROJECT                    NaN   \n",
       "\n",
       "                    Position_Extra      Total             Program_Description  \\\n",
       "134338               KINDERGARTEN   50471.810                    KINDERGARTEN   \n",
       "206341                UNDESIGNATED   3477.860   BUILDING IMPROVEMENT SERVICES   \n",
       "326408                     TEACHER  62237.130           Instruction - Regular   \n",
       "364634  PROFESSIONAL-INSTRUCTIONAL     22.300  GENERAL MIDDLE/JUNIOR HIGH SCH   \n",
       "47683   PROFESSIONAL-INSTRUCTIONAL     54.166   GENERAL HIGH SCHOOL EDUCATION   \n",
       "\n",
       "              Fund_Description                         Text_1  \n",
       "134338            General Fund                            NaN  \n",
       "206341                     NaN  BUILDING IMPROVEMENT SERVICES  \n",
       "326408  General Purpose School                            NaN  \n",
       "364634                     NaN            REGULAR INSTRUCTION  \n",
       "47683                      NaN            REGULAR INSTRUCTION  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zf = zipfile.ZipFile('TrainingData.csv.zip')\n",
    "df = pd.read_csv(zf.open('TrainingData.csv'), index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     23\n",
       "float64     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 FTE         Total\n",
      "count  122952.000000  3.926440e+05\n",
      "mean        0.406381  1.273851e+04\n",
      "std         0.447964  3.696233e+05\n",
      "min         0.000000 -8.746631e+07\n",
      "25%         0.000000  7.231000e+01\n",
      "50%         0.100000  4.464695e+02\n",
      "75%         1.000000  3.429875e+03\n",
      "max         1.000000  1.297000e+08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'num employees')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = df[~((df['FTE']>1) | (df['FTE']<0))]\n",
    "\n",
    "# Print the summary statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(df['FTE'].dropna())\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of %full-time \\n employee works')\n",
    "plt.xlabel('% of full-time')\n",
    "plt.ylabel('num employees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the labels as categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function            category\n",
      "Use                 category\n",
      "Sharing             category\n",
      "Reporting           category\n",
      "Student_Type        category\n",
      "Position_Type       category\n",
      "Object_Type         category\n",
      "Pre_K               category\n",
      "Operating_Status    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "LABELS = ['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type', 'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status']\n",
    "\n",
    "# Define the lambda function: categorize_label\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "\n",
    "# Convert df[LABELS] to a categorical type\n",
    "df[LABELS] = df[LABELS].apply(categorize_label, axis = 0)\n",
    "\n",
    "# Print the converted dtypes\n",
    "print(df[LABELS].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of unique values')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate number of unique values for each label: num_unique_labels\n",
    "num_unique_labels = df[LABELS].apply(pd.Series.nunique)\n",
    "\n",
    "# Plot number of unique values for each label\n",
    "num_unique_labels.plot(kind = 'bar')\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Number of unique values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a simple first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a train-test split in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def multilabel_sample(y, size=1000, min_count=5, seed=None):\n",
    "    \"\"\" Takes a matrix of binary labels `y` and returns\n",
    "        the indices for a sample of size `size` if\n",
    "        `size` > 1 or `size` * len(y) if size =< 1.\n",
    "        The sample is guaranteed to have > `min_count` of\n",
    "        each label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if (np.unique(y).astype(int) != np.array([0, 1])).any():\n",
    "            raise ValueError()\n",
    "    except (TypeError, ValueError):\n",
    "        raise ValueError('multilabel_sample only works with binary indicator matrices')\n",
    "\n",
    "    if (y.sum(axis=0) < min_count).any():\n",
    "        raise ValueError('Some classes do not have enough examples. Change min_count if necessary.')\n",
    "\n",
    "    if size <= 1:\n",
    "        size = np.floor(y.shape[0] * size)\n",
    "\n",
    "    if y.shape[1] * min_count > size:\n",
    "        msg = \"Size less than number of columns * min_count, returning {} items instead of {}.\"\n",
    "        warn(msg.format(y.shape[1] * min_count, size))\n",
    "        size = y.shape[1] * min_count\n",
    "\n",
    "    rng = np.random.RandomState(seed if seed is not None else np.random.randint(1))\n",
    "\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        choices = y.index\n",
    "        y = y.values\n",
    "    else:\n",
    "        choices = np.arange(y.shape[0])\n",
    "\n",
    "    sample_idxs = np.array([], dtype=choices.dtype)\n",
    "\n",
    "    # first, guarantee > min_count of each label\n",
    "    for j in range(y.shape[1]):\n",
    "        label_choices = choices[y[:, j] == 1]\n",
    "        label_idxs_sampled = rng.choice(label_choices, size=min_count, replace=False)\n",
    "        sample_idxs = np.concatenate([label_idxs_sampled, sample_idxs])\n",
    "\n",
    "    sample_idxs = np.unique(sample_idxs)\n",
    "\n",
    "    # now that we have at least min_count of each, we can just random sample\n",
    "    sample_count = int(size - sample_idxs.shape[0])\n",
    "\n",
    "    # get sample_count indices from remaining choices\n",
    "    remaining_choices = np.setdiff1d(choices, sample_idxs)\n",
    "    remaining_sampled = rng.choice(remaining_choices,\n",
    "                                   size=sample_count,\n",
    "                                   replace=False)\n",
    "\n",
    "    return np.concatenate([sample_idxs, remaining_sampled])\n",
    "\n",
    "\n",
    "def multilabel_sample_dataframe(df, labels, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a dataframe `df` and returns a sample of size `size` where all\n",
    "        classes in the binary matrix `labels` are represented at\n",
    "        least `min_count` times.\n",
    "    \"\"\"\n",
    "    idxs = multilabel_sample(labels, size=size, min_count=min_count, seed=seed)\n",
    "    return df.loc[idxs]\n",
    "\n",
    "\n",
    "def multilabel_train_test_split(X, Y, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a features matrix `X` and a label matrix `Y` and\n",
    "        returns (X_train, X_test, Y_train, Y_test) where all\n",
    "        classes in Y are represented at least `min_count` times.\n",
    "    \"\"\"\n",
    "    index = Y.index if isinstance(Y, pd.DataFrame) else np.arange(Y.shape[0])\n",
    "\n",
    "    test_set_idxs = multilabel_sample(Y, size=size, min_count=min_count, seed=seed)\n",
    "    train_set_idxs = np.setdiff1d(index, test_set_idxs)\n",
    "\n",
    "    test_set_mask = index.isin(test_set_idxs)\n",
    "    train_set_mask = ~test_set_mask\n",
    "\n",
    "    return (X[train_set_mask], X[test_set_mask], Y[train_set_mask], Y[test_set_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 317727 entries, 134338 to 415831\n",
      "Data columns (total 2 columns):\n",
      "FTE      317727 non-null float64\n",
      "Total    317727 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 7.3 MB\n",
      "None\n",
      "\n",
      "X_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 79431 entries, 326408 to 413949\n",
      "Data columns (total 2 columns):\n",
      "FTE      79431 non-null float64\n",
      "Total    79431 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.8 MB\n",
      "None\n",
      "\n",
      "y_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 317727 entries, 134338 to 415831\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 33.9 MB\n",
      "None\n",
      "\n",
      "y_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 79431 entries, 326408 to 413949\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 8.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "NUMERIC_COLUMNS = ['FTE', 'Total']\n",
    "LABELS = ['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type', 'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status']\n",
    "\n",
    "# Create the new DataFrame: numeric_data_only\n",
    "numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n",
    "                                                               label_dummies,\n",
    "                                                               size=0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Print the info\n",
    "print(\"X_train info:\")\n",
    "print(X_train.info())\n",
    "print(\"\\nX_test info:\")  \n",
    "print(X_test.info())\n",
    "print(\"\\ny_train info:\")  \n",
    "print(y_train.info())\n",
    "print(\"\\ny_test info:\")  \n",
    "print(y_test.info()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 3.776862937643993e-05\n"
     ]
    }
   ],
   "source": [
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Create the DataFrame: numeric_data_only\n",
    "numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n",
    "                                                               label_dummies,\n",
    "                                                               size=0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression(solver = 'liblinear'))\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the model to predict values on holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the holdout data: holdout\n",
    "holdout = pd.read_csv('TestData.csv', index_col = 0)\n",
    "\n",
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.58980413e-02, 6.65105995e-03, 8.02349469e-04, ...,\n",
       "        1.69749819e-01, 1.98636218e-02, 8.10444069e-01],\n",
       "       [3.59185581e-02, 6.65101624e-03, 8.02353335e-04, ...,\n",
       "        1.69742439e-01, 1.98633226e-02, 8.10457998e-01],\n",
       "       [1.20863618e-01, 1.08113150e-02, 1.04318002e-03, ...,\n",
       "        4.01708136e-02, 5.85445438e-02, 9.47569896e-01],\n",
       "       ...,\n",
       "       [1.25268952e-01, 1.08064423e-02, 1.04352631e-03, ...,\n",
       "        4.00319664e-02, 5.84862242e-02, 9.47879313e-01],\n",
       "       [1.25626122e-01, 1.08033600e-02, 1.04342267e-03, ...,\n",
       "        4.00491484e-02, 5.84498166e-02, 9.47873277e-01],\n",
       "       [1.25222809e-01, 1.08037986e-02, 1.04339148e-03, ...,\n",
       "        4.00616397e-02, 5.84550638e-02, 9.47845478e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing out y results to a csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))\n",
    "\n",
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS]).columns,\n",
    "                             index=holdout.index,\n",
    "                             data=predictions)\n",
    "\n",
    "\n",
    "# Save prediction_df to csv\n",
    "prediction_df.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a bag-of-words in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 385 tokens in Position_Extra if we split on non-alpha numeric\n",
      "['1st', '2nd', '3rd', '4th', '56', '5th', '9th', 'a', 'ab', 'accountability', 'adaptive', 'addit', 'additional', 'adm', 'admin']\n"
     ]
    }
   ],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill missing values in df.Position_Extra\n",
    "df.Position_Extra.fillna('', inplace = True)\n",
    "\n",
    "# Instantiate the CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern = TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit to the data\n",
    "vec_alphanumeric.fit(df.Position_Extra)\n",
    "\n",
    "# Print the number of tokens and first 15 tokens\n",
    "msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric\"\n",
    "print(msg.format(len(vec_alphanumeric.get_feature_names())))\n",
    "print(vec_alphanumeric.get_feature_names()[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining text columns for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combine_text_columns()\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis = 1)\n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna('', inplace = True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's in a token?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4751 tokens in the dataset\n",
      "There are 3282 alpha-numeric tokens in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the basic token pattern\n",
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "# Create the alphanumeric token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate basic CountVectorizer: vec_basic\n",
    "vec_basic = CountVectorizer(token_pattern = TOKENS_BASIC)\n",
    "\n",
    "# Instantiate alphanumeric CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern = TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(df)\n",
    "\n",
    "# Fit and transform vec_basic\n",
    "vec_basic.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_basic\n",
    "print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names())))\n",
    "\n",
    "# Fit and transform vec_alphanumeric\n",
    "vec_alphanumeric.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_alphanumeric\n",
    "print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numeric</th>\n",
       "      <th>text</th>\n",
       "      <th>with_missing</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.856306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.433240</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.973454</td>\n",
       "      <td>foo</td>\n",
       "      <td>4.310229</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.829785</td>\n",
       "      <td>foo bar</td>\n",
       "      <td>2.469828</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-15.062947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.852981</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.786003</td>\n",
       "      <td>foo bar</td>\n",
       "      <td>1.826475</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     numeric     text  with_missing label\n",
       "0 -10.856306      NaN      4.433240     b\n",
       "1   9.973454      foo      4.310229     b\n",
       "2   2.829785  foo bar      2.469828     a\n",
       "3 -15.062947      NaN      2.852981     b\n",
       "4  -5.786003  foo bar      1.826475     a"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.read_csv('sample.csv')\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on sample data - numeric, no nans:  0.7\n"
     ]
    }
   ],
   "source": [
    "# Import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import other necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Split and select numeric data only, no nans \n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=22)\n",
    "\n",
    "# Instantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - numeric, no nans: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on sample data - all numeric, incl nans:  0.7166666666666667\n"
     ]
    }
   ],
   "source": [
    "# Import the Imputer object\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Create training and test sets using only numeric data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=456)\n",
    "\n",
    "# Insantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('imp', Imputer()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - all numeric, incl nans: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on sample data - just text data:  0.8\n"
     ]
    }
   ],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sample_df['text'].fillna('', inplace = True)\n",
    "\n",
    "# Split out only the text data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df['text'],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=456)\n",
    "\n",
    "# Instantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('vec', CountVectorizer()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - just text data: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple types of processing: FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Data\n",
      "0           \n",
      "1        foo\n",
      "2    foo bar\n",
      "3           \n",
      "4    foo bar\n",
      "Name: text, dtype: object\n",
      "\n",
      "Numeric Data\n",
      "     numeric  with_missing\n",
      "0 -10.856306      4.433240\n",
      "1   9.973454      4.310229\n",
      "2   2.829785      2.469828\n",
      "3 -15.062947      2.852981\n",
      "4  -5.786003      1.826475\n"
     ]
    }
   ],
   "source": [
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Obtain the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
    "\n",
    "# Obtain the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[['numeric', 'with_missing']], validate=False)\n",
    "\n",
    "# Fit and transform the text data: just_text_data\n",
    "just_text_data = get_text_data.fit_transform(sample_df)\n",
    "\n",
    "# Fit and transform the numeric data: just_numeric_data\n",
    "just_numeric_data = get_numeric_data.fit_transform(sample_df)\n",
    "\n",
    "# Print head to check results\n",
    "print('Text Data')\n",
    "print(just_text_data.head())\n",
    "print('\\nNumeric Data')\n",
    "print(just_numeric_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple types of processing: FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on sample data - all data:  0.85\n"
     ]
    }
   ],
   "source": [
    "# Import FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Split using ALL data in sample_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing', 'text']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=22)\n",
    "\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - all data: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using FunctionTransformer on the main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Get the dummy encoding of the labels\n",
    "dummy_labels = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Get the columns that are features in the original df\n",
    "NON_LABELS = [c for c in df.columns if c not in LABELS]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],\n",
    "                                                               dummy_labels,\n",
    "                                                               0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Preprocess the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate = False)\n",
    "\n",
    "# Preprocess the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a model to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on budget dataset:  0.3442988253956264\n"
     ]
    }
   ],
   "source": [
    "# Complete the pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a different class of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on budget dataset:  0.9127292870541728\n"
     ]
    }
   ],
   "source": [
    "# Import random forest classifer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Edit model step in pipeline\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier(n_estimators = 15))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from the experts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deciding what's a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00a', '12', '1st', '2nd', '3rd', '4th', '5', '56', '5th', '6']\n"
     ]
    }
   ],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(X_train)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate the CountVectorizer: text_features\n",
    "text_features = CountVectorizer(token_pattern = TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit text_features to the text vector\n",
    "text_features.fit(text_vector)\n",
    "\n",
    "# Print the first 10 tokens\n",
    "print(text_features.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram range in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Import other preprocessing modules\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "# Select 300 best features\n",
    "chi_k = 300\n",
    "\n",
    "# Import functional utilities\n",
    "from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Perform preprocessing\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                   ngram_range=(1,2))),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement interaction modeling in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class SparseInteractions(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, degree=2, feature_name_separator=\"_\"):\n",
    "        self.degree = degree\n",
    "        self.feature_name_separator = feature_name_separator\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not sparse.isspmatrix_csc(X):\n",
    "            X = sparse.csc_matrix(X)\n",
    "\n",
    "        if hasattr(X, \"columns\"):\n",
    "            self.orig_col_names = X.columns\n",
    "        else:\n",
    "            self.orig_col_names = np.array([str(i) for i in range(X.shape[1])])\n",
    "\n",
    "        spi = self._create_sparse_interactions(X)\n",
    "        return spi\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return self.feature_names\n",
    "\n",
    "    def _create_sparse_interactions(self, X):\n",
    "        out_mat = []\n",
    "        self.feature_names = self.orig_col_names.tolist()\n",
    "\n",
    "        for sub_degree in range(2, self.degree + 1):\n",
    "            for col_ixs in combinations(range(X.shape[1]), sub_degree):\n",
    "                # add name for new column\n",
    "                name = self.feature_name_separator.join(self.orig_col_names[list(col_ixs)])\n",
    "                self.feature_names.append(name)\n",
    "\n",
    "                # get column multiplications value\n",
    "                out = X[:, col_ixs[0]]\n",
    "                for j in col_ixs[1:]:\n",
    "                    out = out.multiply(X[:, j])\n",
    "\n",
    "                out_mat.append(out)\n",
    "\n",
    "        return sparse.hstack([X] + out_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                   ngram_range=(1, 2))),  \n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree = 2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the hashing trick in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  0.377964\n",
      "1  0.755929\n",
      "2  0.377964\n",
      "3  0.377964\n",
      "4  0.200000\n"
     ]
    }
   ],
   "source": [
    "# Import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Get text data: text_data\n",
    "text_data = combine_text_columns(X_train)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)' \n",
    "\n",
    "# Instantiate the HashingVectorizer: hashing_vec\n",
    "hashing_vec = HashingVectorizer(token_pattern = TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit and transform the Hashing Vectorizer\n",
    "hashed_text = hashing_vec.fit_transform(text_data)\n",
    "\n",
    "# Create DataFrame and print the head\n",
    "hashed_df = pd.DataFrame(hashed_text.data)\n",
    "print(hashed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the hashing vectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Instantiate the winning model pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                     non_negative=True, norm=None, binary=False,\n",
    "                                                     ngram_range=(1,2))),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree=2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
