{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1 - ARMA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exploration\n",
    "\n",
    "# Import modules\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load in the time series\n",
    "candy = pd.read_csv('candy_production.csv', \n",
    "                    index_col='date',\n",
    "                    parse_dates=True)\n",
    "\n",
    "# Plot and show the time series on axis ax\n",
    "fig, ax = plt.subplots()\n",
    "candy.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train-test splits\n",
    "\n",
    "# Split the data into a train and test set\n",
    "candy_train = candy.loc[:'2006'] \n",
    "candy_test = candy.loc['2007':] \n",
    "\n",
    "# Create an axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the train and test sets on the axis ax\n",
    "candy_train.plot(ax=ax)\n",
    "candy_test.plot(ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Is it stationary\n",
    "\n",
    "df1.pct_change().dropna().plot(); plt.show()\n",
    "_______________________________________________\n",
    "\n",
    "df2.pct_change().dropna().plot(); plt.show()\n",
    "_______________________________________________\n",
    "\n",
    "df3.pct_change().dropna().plot(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Augmented Dicky-Fuller\n",
    "\n",
    "# Import augmented dicky-fuller test function\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Run test\n",
    "result = adfuller(earthquake['earthquakes_per_year'])\n",
    "\n",
    "# Print test statistic\n",
    "print(result[0])\n",
    "\n",
    "# Print p-value\n",
    "print(result[1])\n",
    "\n",
    "# Print critical values\n",
    "print(result[4]) \n",
    "\n",
    "# <script.py> output:\n",
    "#     -3.183192251191782\n",
    "#     0.02097842525600371\n",
    "#     {'1%': -3.5003788874873405, '5%': -2.8921519665075235, '10%': -2.5830997960069446}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking the difference\n",
    "\n",
    "# Run the ADF test on the time series\n",
    "result = adfuller(city['city_population'])\n",
    "\n",
    "# Plot the time series\n",
    "fig, ax = plt.subplots()\n",
    "city.plot(ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# Print the test statistic and the p-value\n",
    "print('ADF Statistic:', result[0])\n",
    "print('p-value:', result[1])\n",
    "__________________________________________\n",
    "\n",
    "# Calculate the first difference of the time series\n",
    "city_stationary = city.diff().dropna()\n",
    "\n",
    "# Run ADF test on the differenced time series\n",
    "result = adfuller(city_stationary['city_population'])\n",
    "\n",
    "# Plot the differenced time series\n",
    "fig, ax = plt.subplots()\n",
    "city_stationary.plot(ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# Print the test statistic and the p-value\n",
    "print('ADF Statistic:', result[0])\n",
    "print('p-value:', result[1])\n",
    "\n",
    "# <script.py> output:\n",
    "#     ADF Statistic: -0.8146211646181589\n",
    "#     p-value: 0.8147894381484937\n",
    "______________________________________________\n",
    "\n",
    "# Calculate the second difference of the time series\n",
    "city_stationary = city.diff().diff().dropna()\n",
    "\n",
    "# Run ADF test on the differenced time series\n",
    "result = adfuller(city_stationary['city_population'])\n",
    "\n",
    "# Plot the differenced time series\n",
    "fig, ax = plt.subplots()\n",
    "city_stationary.plot(ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# Print the test statistic and the p-value\n",
    "print('ADF Statistic:', result[0])\n",
    "print('p-value:', result[1])\n",
    "\n",
    "# <script.py> output:\n",
    "#     ADF Statistic: -6.43364603291874\n",
    "#     p-value: 1.673449851040049e-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Other tranforms\n",
    "\n",
    "# Calculate the first difference and drop the nans\n",
    "amazon_diff = amazon.diff().dropna()\n",
    "\n",
    "# Run test and print\n",
    "result_diff = adfuller(amazon_diff['close'])\n",
    "print(result_diff)\n",
    "____________________________________________________\n",
    "\n",
    "# Calculate the first difference and drop the nans\n",
    "amazon_diff = amazon.diff().dropna()\n",
    "\n",
    "# Run test and print\n",
    "result_diff = adfuller(amazon_diff['close'])\n",
    "print(result_diff)\n",
    "\n",
    "# Calculate log-return and drop nans\n",
    "amazon_log = np.log(amazon[1:]/amazon.shift().dropna())\n",
    "\n",
    "# Run test and print\n",
    "result_log = adfuller(amazon_log['close'])\n",
    "print(result_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating ARMA data\n",
    "\n",
    "# Import data generation function and set random seed\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "np.random.seed(1)\n",
    "\n",
    "# Set coefficients\n",
    "ar_coefs = [1]\n",
    "ma_coefs = [1, -.7]\n",
    "\n",
    "# Generate data\n",
    "y = arma_generate_sample(ar_coefs, ma_coefs, nsample=100, sigma=0.5, )\n",
    "\n",
    "plt.plot(y)\n",
    "plt.ylabel(r'$y_t$')\n",
    "plt.xlabel(r'$t$')\n",
    "plt.show()\n",
    "_______________________________________________________________\n",
    "\n",
    "# Import data generation function and set random seed\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "np.random.seed(2)\n",
    "\n",
    "# Set coefficients\n",
    "ar_coefs = [1, -0.3, -0.2]\n",
    "ma_coefs = [1]\n",
    "\n",
    "# Generate data\n",
    "y = arma_generate_sample(ar_coefs, ma_coefs, nsample=100, sigma=0.5, )\n",
    "\n",
    "plt.plot(y)\n",
    "plt.ylabel(r'$y_t$')\n",
    "plt.xlabel(r'$t$')\n",
    "plt.show()\n",
    "______________________________________________________________\n",
    "\n",
    "# Import data generation function and set random seed\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "np.random.seed(3)\n",
    "\n",
    "# Set coefficients\n",
    "ar_coefs = [1, 0.2, ]\n",
    "ma_coefs = [1, 0.3, 0.4]\n",
    "\n",
    "# Generate data\n",
    "y = arma_generate_sample(ar_coefs, ma_coefs, nsample=100, sigma=0.5, )\n",
    "\n",
    "plt.plot(y)\n",
    "plt.ylabel(r'$y_t$')\n",
    "plt.xlabel(r'$t$')\n",
    "plt.show()\n",
    "_____________________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting Prelude\n",
    "\n",
    "# Import the ARMA model\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "\n",
    "# Instantiate the model\n",
    "model = ARMA(y, order=(1,1))\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2 - Fitting the Future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting AR and MA models\n",
    "\n",
    "\n",
    "\n",
    "_____________________________________________\n",
    "\n",
    "# Instantiate the model\n",
    "model = ARMA(sample['timeseries_2'], order=(0,3))\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print summary\n",
    "print(results.summary())\n",
    "\n",
    "# The fitted models had very similar AR and MA coefficient \n",
    "# values to the real ones! You know it works!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting an ARMA model\n",
    "\n",
    "# Instantiate the model\n",
    "model = ARMA(earthquake, order=(3,1))\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print model fit summary\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting an ARMAX model\n",
    "\n",
    "# Instantiate the model\n",
    "model = ARMA(hospital['wait_times_hrs'], order=(2,1), exog=hospital['nurse_count'])\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print model fit summary\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating one-step-ahead predictions\n",
    "\n",
    "# Generate predictions\n",
    "one_step_forecast = results.get_prediction(start=-30)\n",
    "\n",
    "# Extract prediction mean\n",
    "mean_forecast = one_step_forecast.predicted_mean\n",
    "\n",
    "# Get confidence intervals of  predictions\n",
    "confidence_intervals = one_step_forecast.conf_int()\n",
    "\n",
    "# Select lower and upper confidence limits\n",
    "lower_limits = confidence_intervals.loc[:,'lower close']\n",
    "upper_limits = confidence_intervals.loc[:,'upper close']\n",
    "\n",
    "# Print best estimate  predictions\n",
    "print(mean_forecast)\n",
    "\n",
    "\n",
    "# <script.py> output:\n",
    "#     date\n",
    "#     2019-01-10    1648.652293\n",
    "#     2019-01-11    1658.189380\n",
    "#     2019-01-12    1635.154150\n",
    "#     2019-01-13    1606.230818\n",
    "#     2019-01-14    1595.914111\n",
    "#     Freq: D, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting one-step-ahead predictions\n",
    "\n",
    "# plot the amazon data\n",
    "plt.plot(amazon.index, amazon, label='observed')\n",
    "\n",
    "# plot your mean predictions\n",
    "plt.plot(mean_forecast.index, mean_forecast, color='r', label='forecast')\n",
    "\n",
    "# shade the area between your confidence limits\n",
    "plt.fill_between(lower_limits.index, \n",
    "                 lower_limits,\n",
    "\t\t         upper_limits, color='pink')\n",
    "\n",
    "# set labels, legends and show plot\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Amazon Stock Price - Close USD')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating dynamic forecasts\n",
    "\n",
    "# Generate predictions\n",
    "dynamic_forecast = results.get_prediction(start=-30, dynamic=True)\n",
    "\n",
    "# Extract prediction mean\n",
    "mean_forecast = dynamic_forecast.predicted_mean\n",
    "\n",
    "# Get confidence intervals of predictions\n",
    "confidence_intervals = dynamic_forecast.conf_int()\n",
    "\n",
    "# Select lower and upper confidence limits\n",
    "lower_limits = confidence_intervals.loc[:,'lower close']\n",
    "upper_limits = confidence_intervals.loc[:,'upper close']\n",
    "\n",
    "# Print best estimate predictions\n",
    "print(mean_forecast.head())\n",
    "\n",
    "\n",
    "# <script.py> output:\n",
    "#     date\n",
    "#     2019-01-10    1648.652293\n",
    "#     2019-01-11    1648.759348\n",
    "#     2019-01-12    1649.121832\n",
    "#     2019-01-13    1645.696257\n",
    "#     2019-01-14    1643.130812\n",
    "#     Freq: D, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting dynamic forecasts\n",
    "\n",
    "# plot the amazon data\n",
    "plt.plot(amazon.index, amazon, label='observed')\n",
    "\n",
    "# plot your mean forecast\n",
    "plt.plot(mean_forecast.index, mean_forecast, color='r', label='forecast')\n",
    "\n",
    "# shade the area between your confidence limits\n",
    "plt.fill_between(lower_limits.index, lower_limits, \n",
    "                 upper_limits, color='pink')\n",
    "\n",
    "# set labels, legends and show plot\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Amazon Stock Price - Close USD')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Differencing and fitting ARMA\n",
    "\n",
    "# Take the first difference of the data\n",
    "amazon_diff = amazon.diff().dropna()\n",
    "\n",
    "# Create ARMA(2,2) model\n",
    "arma = SARIMAX(amazon_diff, order=(2,0,2))\n",
    "\n",
    "# Fit model\n",
    "arma_results = arma.fit()\n",
    "\n",
    "# Print fit summary\n",
    "print(arma_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unrolling ARMA forecast\n",
    "\n",
    "# Make arma forecast of next 10 differences\n",
    "arma_diff_forecast = arma_results.get_forecast(steps=10).predicted_mean\n",
    "\n",
    "# Integrate the difference forecast\n",
    "arma_int_forecast = np.cumsum(arma_diff_forecast)\n",
    "\n",
    "# Make absolute value forecast\n",
    "arma_value_forecast = arma_int_forecast + amazon.iloc[-1,0]\n",
    "\n",
    "# Print forecast\n",
    "print(arma_value_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "\n",
    "# Create ARIMA(2,1,2) model\n",
    "arima = SARIMAX(amazon, order=(2,1,2))\n",
    "\n",
    "# Fit ARIMA model\n",
    "arima_results = arima.fit()\n",
    "\n",
    "# Make ARIMA forecast of next 10 values\n",
    "arima_value_forecast = arima_results.get_forecast(steps=10).predicted_mean\n",
    "\n",
    "# Print forecast\n",
    "print(arima_value_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3 - The Best of the Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AR or MA\n",
    "\n",
    "# Import\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Create figure\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(12,8))\n",
    " \n",
    "# Plot the ACF of df\n",
    "plot_acf(df, lags=10, zero=False, ax=ax1)\n",
    "\n",
    "# Plot the PACF of df\n",
    "plot_pacf(df, lags=10, zero=False, ax=ax2)\n",
    "\n",
    "plt.show()\n",
    "___________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Order of earthquakes\n",
    "\n",
    "# Create figure\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(12,8))\n",
    "\n",
    "# Plot ACF and PACF\n",
    "plot_acf(earthquake, lags=15, zero=False, ax=ax1)\n",
    "plot_pacf(earthquake, lags=15, zero=False, ax=ax2)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "__________________________________________________\n",
    "\n",
    "# Create figure\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(12,8))\n",
    "\n",
    "# Plot ACF and PACF\n",
    "plot_acf(earthquake, lags=10, zero=False, ax=ax1)\n",
    "plot_pacf(earthquake, lags=10, zero=False, ax=ax2)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Instantiate model\n",
    "model = SARIMAX(earthquake, order=(1,0,0))\n",
    "\n",
    "# Train model\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Searching over model order\n",
    "\n",
    "# Create empty list to store search results\n",
    "order_aic_bic=[]\n",
    "\n",
    "# Loop over p values from 0-2\n",
    "for p in range(3):\n",
    "  # Loop over q values from 0-2\n",
    "    for q in range(3):\n",
    "      \t# create and fit ARMA(p,q) model\n",
    "        model = SARIMAX(df, order=(p,0,q))\n",
    "        results = model.fit()\n",
    "        \n",
    "        # Append order and results tuple\n",
    "        order_aic_bic.append((p, q, results.aic, results.bic))\n",
    "        \n",
    "# We built 9 models in just a few seconds! \n",
    "# In the next exercise you will evaluate the results to choose the best model."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In [2]: order_aic_bic\n",
    "Out[2]: \n",
    "[(0, 0, 1615.4938702439326, 1619.7084783423547),\n",
    " (0, 1, 1429.9887238080628, 1438.4179400049072),\n",
    " (0, 2, 1425.057439342412, 1437.7012636376785),\n",
    " (1, 0, 1497.3075314843609, 1505.7367476812053),\n",
    " (1, 1, 1428.051695490869, 1440.6955197861355),\n",
    " (1, 2, 1417.029938509204, 1433.8883709028928),\n",
    " (2, 0, 1419.1094544183852, 1431.7532787136518),\n",
    " (2, 1, 1414.2486791507986, 1431.1071115444875),\n",
    " (2, 2, 1416.0848919485434, 1437.1579324406543)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choosing order with AIC and BIC\n",
    "\n",
    "# Construct DataFrame from order_aic_bic\n",
    "order_df = pd.DataFrame(order_aic_bic, \n",
    "                        columns=['p','q', 'AIC', 'BIC'])\n",
    "\n",
    "# Print order_df in order of increasing AIC\n",
    "print(order_df.sort_values('AIC'))\n",
    "\n",
    "# Print order_df in order of increasing BIC\n",
    "print(order_df.sort_values('BIC'))\n",
    "____________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AIC and BIC vs ACF and PACF\n",
    "\n",
    "# Loop over p values from 0-2\n",
    "for p in range(3):\n",
    "    # Loop over q values from 0-2\n",
    "    for q in range(3):\n",
    "      \n",
    "        try:\n",
    "            # create and fit ARMA(p,q) model\n",
    "            model = SARIMAX(earthquake, order=(p, 0, q))\n",
    "            results = model.fit()\n",
    "            \n",
    "            # Print order and results\n",
    "            print(p, q, results.aic, results.bic)\n",
    "            \n",
    "        except:\n",
    "            print(p, q, None, None)     "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    0 0 888.4297722924081 891.0248921425426\n",
    "    0 1 799.6741727812073 804.8644124814765\n",
    "    0 2 761.0674787503889 768.8528383007927\n",
    "    1 0 666.6455255041611 671.8357652044303\n",
    "    1 1 647.1322999673815 654.9176595177853\n",
    "    1 2 648.7385664620634 659.1190458626018\n",
    "    2 0 656.0283744146391 663.8137339650428\n",
    "    2 1 None None\n",
    "    2 2 648.8506443429098 661.8262435935828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mean absolute error\n",
    "\n",
    "# Fit model\n",
    "model = SARIMAX(earthquake, order=(1,0,1))\n",
    "results = model.fit()\n",
    "\n",
    "# Calculate the mean absolute error from residuals\n",
    "mae = np.mean(np.abs(results.resid))\n",
    "\n",
    "# Print mean absolute error\n",
    "print(mae)\n",
    "\n",
    "# Make plot of time series for comparison\n",
    "earthquake.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Test\t      Null hypothesis\t                            P-value name\n",
    "Ljung-Box\t  There are no correlations in the residual     Prob(Q)\n",
    "Jarque-Bera   The residuals are normally distributed\t    Prob(JB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Diagnostic summary statistics\n",
    "\n",
    "# Create and fit model\n",
    "model1 = SARIMAX(df, order=(3,0,1))\n",
    "results1 = model1.fit()\n",
    "\n",
    "# Print summary\n",
    "print(results1.summary())\n",
    "__________________________________\n",
    "\n",
    "# Create and fit model\n",
    "model2 = SARIMAX(df, order=(2,0,0))\n",
    "results2 = model2.fit()\n",
    "\n",
    "# Print summary\n",
    "print(results2.fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot diagnostics\n",
    "\n",
    "# Create and fit model\n",
    "model = SARIMAX(df, order=(1,1,1))\n",
    "results=model.fit()\n",
    "\n",
    "# Create the 4 diagostics plots\n",
    "results.plot_diagnostics()\n",
    "plt.show()\n",
    "_____________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test\t                       # Good fit\n",
    "Standardized residual\t       There are no obvious patterns in the residuals\n",
    "Histogram plus kde estimate\t   The KDE curve should be very similar to the normal distribution\n",
    "Normal Q-Q\t                   Most of the data points should lie on the straight line\n",
    "Correlogram\t                   95% of correlations for lag greater than one should not be significant\n",
    "\n",
    "If the Q-Q plot deviates significantly from a straight line! This suggests the model could be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identification\n",
    "\n",
    "# Plot time series\n",
    "savings.plot()\n",
    "plt.show()\n",
    "\n",
    "# Run Dicky-Fuller test\n",
    "result = adfuller(savings['savings'])\n",
    "\n",
    "# Print test statistic\n",
    "print(result)\n",
    "\n",
    "# Print p-value\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identification II\n",
    "\n",
    "# Create figure\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(12,8))\n",
    " \n",
    "# Plot the ACF of savings on ax1\n",
    "plot_acf(savings, lags=10, ax=ax1, zero=False)\n",
    "\n",
    "# Plot the PACF of savings on ax2\n",
    "plot_pacf(savings, lags=10, ax=ax2, zero=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estimation\n",
    "\n",
    "# Loop over p values from 0-3\n",
    "for p in range(4):\n",
    "  \n",
    "  # Loop over q values from 0-3\n",
    "    for q in range(4):\n",
    "      try:\n",
    "        # Create and fit ARMA(p,q) model\n",
    "        model = SARIMAX(savings, order=(p, 0, q), trend='c')\n",
    "        results = model.fit()\n",
    "        \n",
    "        # Print p, q, AIC, BIC\n",
    "        print(p, q, results.aic, results.bic)\n",
    "        \n",
    "      except:\n",
    "        print(p, q, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Diagnostics\n",
    "\n",
    "# Create and fit model\n",
    "model = SARIMAX(savings, order=(1,0,2))\n",
    "results = model.fit()\n",
    "\n",
    "# Create the 4 diagostics plots\n",
    "results.plot_diagnostics()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4 - Seasonal ARIMA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seasonal Decompose\n",
    "\n",
    "# Import seasonal decompose\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Perform additive decomposition\n",
    "decomp = seasonal_decompose(milk_production['pounds_per_cow'], \n",
    "                            freq=12)\n",
    "\n",
    "# Plot decomposition\n",
    "decomp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seasonal ACF and PACF\n",
    "\n",
    "# Create figure and subplot\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot the ACF on ax1\n",
    "plot_acf(water['water_consumers'], lags=25, zero=False,  ax=ax1)\n",
    "\n",
    "# Show figure\n",
    "plt.show()\n",
    "__________________________________________________\n",
    "\n",
    "# Subtract the rolling mean\n",
    "water_2 = water - water.rolling(15).mean()\n",
    "\n",
    "# Drop the NaN values\n",
    "water_2 = water_2.dropna()\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot the ACF\n",
    "plot_acf(water_2['water_consumers'], lags=25, zero=False, ax=ax1)\n",
    "\n",
    "# Show figure\n",
    "plt.show()\n",
    "___________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting SARIMA models\n",
    "\n",
    "# Create a SARIMAX model\n",
    "model = SARIMAX(df1, order=(1,0,0), seasonal_order=(1,1,0,7))\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the results summary\n",
    "print(results.summary())\n",
    "_________________________________________\n",
    "\n",
    "# Create a SARIMAX model\n",
    "model = SARIMAX(df2, order=(2,1,1), seasonal_order=(1,0,0,4))\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the results summary\n",
    "print(results.summary())\n",
    "_________________________________________\n",
    "\n",
    "# Create a SARIMAX model\n",
    "model = SARIMAX(df3, order=(1,1,0), seasonal_order=(0,1,1,12))\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the results summary\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "        AR(p)\t                MA(q)               \tARMA(p,q)\n",
    "ACF  \tTails off           \tCuts off after lag q\tTails off\n",
    "PACF\tCuts off after lag p\tTails off\t            Tails off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choosing SARIMA order\n",
    "\n",
    "# Take the first and seasonal differences and drop NaNs\n",
    "aus_employment_diff = aus_employment - aus_employment.diff().diff(12).dropna()\n",
    "___________________________________________________\n",
    "\n",
    "# Create the figure \n",
    "fig, (ax1, ax2) = plt.subplots(2,1,figsize=(8,6))\n",
    "\n",
    "# Plot the ACF on ax1\n",
    "plot_acf(aus_employment_diff, lags=11, zero=False, ax=ax1)\n",
    "\n",
    "# Plot the PACF on ax2\n",
    "plot_pacf(aus_employment_diff, lags=11, zero=False, ax=ax2)\n",
    "\n",
    "plt.show()\n",
    "__________________________________________________\n",
    "\n",
    "# Make list of lags\n",
    "lags = [12, 24, 36, 48, 60]\n",
    "\n",
    "# Create the figure \n",
    "fig, (ax1, ax2) = plt.subplots(2,1,figsize=(8,6))\n",
    "\n",
    "# Plot the ACF on ax1\n",
    "plot_acf(aus_employment_diff, lags=lags, ax=ax1, zero=False)\n",
    "\n",
    "# Plot the PACF on ax2\n",
    "plot_pacf(aus_employment_diff, lags=lags, ax=ax2, zero=False)\n",
    "\n",
    "plt.show()\n",
    "__________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SARIMA vs ARIMA forecasts\n",
    "\n",
    "# Create ARIMA mean forecast\n",
    "arima_pred = arima_results.get_forecast(steps=25)\n",
    "arima_mean = arima_pred.predicted_mean\n",
    "\n",
    "# Create SARIMA mean forecast\n",
    "sarima_pred = sarima_results.get_forecast(steps=25)\n",
    "sarima_mean = sarima_pred.predicted_mean\n",
    "\n",
    "# Plot mean ARIMA and SARIMA predictions and observed\n",
    "plt.plot(dates, sarima_mean, label='SARIMA')\n",
    "plt.plot(dates, arima_mean, label='ARIMA')\n",
    "plt.plot(wisconsin_test, label='observed')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Automated model selection\n",
    "\n",
    "# Import pmdarima as pm\n",
    "import pmdarima as pm\n",
    "___________________________________________\n",
    "\n",
    "# Create auto_arima model\n",
    "model1 = pm.auto_arima(df1,\n",
    "                      seasonal=1, m=7,\n",
    "                      d=0, D=1, \n",
    "                 \t  max_p=2, max_q=2,\n",
    "                      trace=True,\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True) \n",
    "\n",
    "# Print model summary\n",
    "print(model1.summary())\n",
    "______________________________________________\n",
    "\n",
    "# Create model\n",
    "model2 = pm.auto_arima(df2,\n",
    "                      seasonal=False,\n",
    "                      d=1,\n",
    "                      trend='c',\n",
    "                 \t  max_p=2, max_q=2,\n",
    "                      trace=True,\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True) \n",
    "\n",
    "# Print model summary\n",
    "print(model2.summary())\n",
    "_______________________________________________\n",
    "\n",
    "# Create model for SARIMAX(p,1,q)(P,1,Q)7\n",
    "model3 = pm.auto_arima(df3,\n",
    "                      seasonal=True, m=7,\n",
    "                      d=1, D=1, \n",
    "                      start_p=1, start_q=1,\n",
    "                      max_p=1, max_q=1,\n",
    "                      max_P=1, max_Q=1,\n",
    "                      trace=True,\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True) \n",
    "\n",
    "# Print model summary\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving and updating models\n",
    "\n",
    "# Import joblib\n",
    "import joblib\n",
    "\n",
    "# Set model name\n",
    "filename = 'candy_model.pkl'\n",
    "\n",
    "# Pickle it\n",
    "joblib.dump(model,filename)\n",
    "___________________________________________\n",
    "\n",
    "# Import\n",
    "import joblib\n",
    "\n",
    "# Set model name\n",
    "filename = \"candy_model.pkl\"\n",
    "\n",
    "# Load the model back in\n",
    "loaded_model = joblib.load(filename)\n",
    "__________________________________________\n",
    "\n",
    "# Update the model\n",
    "loaded_model.update(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SARIMA model diagnostics\n",
    "\n",
    "# Import model class\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Create model object\n",
    "model = SARIMAX(co2, \n",
    "                order=(1,1,1), \n",
    "                seasonal_order=(0,1,1,12), \n",
    "                trend='c')\n",
    "# Fit model\n",
    "results = model.fit()\n",
    "___________________________________________________\n",
    "\n",
    "# Plot common diagnostics\n",
    "results.plot_diagnostics()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SARIMA forecast\n",
    "\n",
    "# Create forecast object\n",
    "forecast_object = results.get_forecast(steps=136)\n",
    "\n",
    "# Extract prediction mean\n",
    "mean = forecast_object.predicted_mean\n",
    "\n",
    "# Extract the confidence intervals\n",
    "conf_int = forecast_object.conf_int()\n",
    "\n",
    "# Extract the forecast dates\n",
    "dates = mean.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SARIMA forecast\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot past CO2 levels\n",
    "plt.plot(co2.index, co2, label='past')\n",
    "\n",
    "# Plot the prediction means as line\n",
    "plt.plot(dates, mean, label='predicted')\n",
    "\n",
    "# Shade between the confidence intervals\n",
    "plt.fill_between(dates, conf_int.iloc[:,0], conf_int.iloc[:,1], alpha=0.2)\n",
    "\n",
    "# Plot legend and show figure\n",
    "plt.legend()\n",
    "plt.show()\n",
    "___________________________________________________\n",
    "\n",
    "# Print last predicted mean\n",
    "print(mean[-1])\n",
    "\n",
    "# Print last confidence interval\n",
    "print(conf_int.iloc[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-2.0",
   "language": "python",
   "name": "tf_gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
