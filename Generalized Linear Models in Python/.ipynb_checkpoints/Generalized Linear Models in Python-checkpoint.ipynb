{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generalized Linear Models in Python"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Course Description\n",
    "Imagine being able to handle data where the response variable is either binary, count, or approximately normal, all under one single framework. Well, you don't have to imagine. Enter the Generalized Linear Models in Python course! In this course you will extend your regression toolbox with the logistic and Poisson models, by learning how to fit, understand, assess model performance and finally use the model to make predictions on new data. You will practice using data from real world studies such the largest population poisoning in world's history, nesting of horseshoe crabs and counting the bike crossings on the bridges in New York City."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODULE 1\n",
    "\n",
    "## Introduction to GLMs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Review linear models and learn how GLMs are an extension of the linear model given different types of response variables. You will also learn the building blocks of GLMs and the technical process of fitting a GLM in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear model, a special case of GLM\n",
    "\n",
    "from statsmodels.formula.api import ols, glm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Fit a linear model\n",
    "model_lm = ols(formula = 'Salary ~ Experience',\n",
    "               data = salary).fit()\n",
    "\n",
    "# View model coefficients\n",
    "print(model_lm.params)\n",
    "\n",
    "\n",
    "from statsmodels.formula.api import ols, glm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Fit a GLM\n",
    "model_glm = glm(formula = 'Salary ~ Experience',\n",
    "                data = salary,\n",
    "                family = sm.families.Gaussian()).fit()\n",
    "\n",
    "# View model coefficients\n",
    "print(model_glm.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear model and a binary response variable\n",
    "\n",
    "# Define model formula\n",
    "formula = 'y ~ width'\n",
    "\n",
    "# Define probability distribution for the response variable for the linear and GLM model\n",
    "family_LM = sm.families.Gaussian()\n",
    "family_GLM = sm.families.Binomial()\n",
    "\n",
    "# Define and fit a linear model\n",
    "model_LM = glm(formula = formula, data = crab, family = family_LM).fit()\n",
    "print(model_LM.summary())\n",
    "\n",
    "# Define and fit a logistic regression model\n",
    "model_GLM = glm(formula = formula, data = crab, family = family_GLM).fit()\n",
    "print(model_GLM.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                 Generalized Linear Model Regression Results                  \n",
    "==============================================================================\n",
    "Dep. Variable:                      y   No. Observations:                  173\n",
    "Model:                            GLM   Df Residuals:                      171\n",
    "Model Family:                Gaussian   Df Model:                            1\n",
    "Link Function:               identity   Scale:                         0.19515\n",
    "Method:                          IRLS   Log-Likelihood:                -103.13\n",
    "Date:                Tue, 14 May 2019   Deviance:                       33.371\n",
    "Time:                        21:57:42   Pearson chi2:                     33.4\n",
    "No. Iterations:                     3   Covariance Type:             nonrobust\n",
    "==============================================================================\n",
    "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "Intercept     -1.7655      0.421     -4.190      0.000      -2.591      -0.940\n",
    "width          0.0915      0.016      5.731      0.000       0.060       0.123\n",
    "==============================================================================\n",
    "\n",
    "\n",
    "\n",
    "                 Generalized Linear Model Regression Results                  \n",
    "==============================================================================\n",
    "Dep. Variable:                      y   No. Observations:                  173\n",
    "Model:                            GLM   Df Residuals:                      171\n",
    "Model Family:                Binomial   Df Model:                            1\n",
    "Link Function:                  logit   Scale:                          1.0000\n",
    "Method:                          IRLS   Log-Likelihood:                -97.226\n",
    "Date:                Tue, 14 May 2019   Deviance:                       194.45\n",
    "Time:                        21:57:42   Pearson chi2:                     165.\n",
    "No. Iterations:                     4   Covariance Type:             nonrobust\n",
    "==============================================================================\n",
    "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "Intercept    -12.3508      2.629     -4.698      0.000     -17.503      -7.199\n",
    "width          0.4972      0.102      4.887      0.000       0.298       0.697\n",
    "==============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparing predicted values\n",
    "\n",
    "# View test set\n",
    "print(test)\n",
    "\n",
    "# Compute estimated probabilities for linear model: pred_lm\n",
    "pred_lm = model_LM.predict(test)\n",
    "\n",
    "# Compute estimated probabilities for GLM model: pred_glm\n",
    "pred_glm = model_GLM.predict(test)\n",
    "\n",
    "# Combine test sample & predictions for linear and GLM models\n",
    "predict = pd.DataFrame({'Pred_LM': pred_lm, 'Pred_GLM': pred_glm})\n",
    "\n",
    "# Concatenate test set, predictions pred_LM and pred_GLM into a dataframe and view the results: all_data\n",
    "all_data = pd.concat([test, predict], axis = 1)\n",
    "print(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model fitting step-by-step\n",
    "\n",
    "# Define the formula the the logistic model\n",
    "model_formula = 'switch ~ distance100'\n",
    "\n",
    "# Define the correct probability distribution and the link function of the response variable\n",
    "link_function = sm.families.links.logit\n",
    "model_family = sm.families.Binomial(link = link_function)\n",
    "\n",
    "# Fit the model\n",
    "wells_fit = glm(formula = model_formula, data = wells, family = model_family).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Results of the model fit using summary()\n",
    "\n",
    "# View the results of the wells_fit model\n",
    "wells_fit.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                 Generalized Linear Model Regression Results                  \n",
    "==============================================================================\n",
    "Dep. Variable:                 switch   No. Observations:                 3010\n",
    "Model:                            GLM   Df Residuals:                     3008\n",
    "Model Family:                Binomial   Df Model:                            1\n",
    "Link Function:                  logit   Scale:                          1.0000\n",
    "Method:                          IRLS   Log-Likelihood:                -2029.6\n",
    "Date:                Wed, 15 May 2019   Deviance:                       4059.2\n",
    "Time:                        01:01:44   Pearson chi2:                 3.01e+03\n",
    "No. Iterations:                     4   Covariance Type:             nonrobust\n",
    "===============================================================================\n",
    "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
    "-------------------------------------------------------------------------------\n",
    "Intercept       0.6193      0.061     10.219      0.000       0.501       0.738\n",
    "distance100    -0.6480      0.098     -6.599      0.000      -0.840      -0.456\n",
    "==============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODULE 2\n",
    "\n",
    "### Modeling Binary Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This chapter focuses on logistic regression. You'll learn about the structure of binary data, the logit link function, model fitting, as well as how to interpret model coefficients, model inference, and how to assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute odds and probabilities\n",
    "\n",
    "# Compute the odds\n",
    "odds = 15/(60-15)\n",
    "# Print the result\n",
    "print('Odds are: ', round(odds,3))\n",
    "\n",
    "\n",
    "# Compute the probability\n",
    "probability = 15/60\n",
    "# Print the result\n",
    "print('Probability is ', round(probability,3))\n",
    "\n",
    "\n",
    "# Probability calculation\n",
    "probability = 15/60\n",
    "# Compute odds using probability calculation\n",
    "odds_from_probs = probability/(1 - probability)\n",
    "# Print the results\n",
    "print(round(odds_from_probs,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit logistic regression\n",
    "\n",
    "# Load libraries and functions\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "\n",
    "# Fit logistic regression model\n",
    "model_GLM = glm(formula = 'switch ~ arsenic',\n",
    "                data = wells,\n",
    "                family = sm.families.Binomial()).fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model_GLM.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                 Generalized Linear Model Regression Results                  \n",
    "==============================================================================\n",
    "Dep. Variable:                 switch   No. Observations:                 3020\n",
    "Model:                            GLM   Df Residuals:                     3018\n",
    "Model Family:                Binomial   Df Model:                            1\n",
    "Link Function:                  logit   Scale:                          1.0000\n",
    "Method:                          IRLS   Log-Likelihood:                -2004.3\n",
    "Date:                Wed, 15 May 2019   Deviance:                       4008.7\n",
    "Time:                        12:47:18   Pearson chi2:                 3.04e+03\n",
    "No. Iterations:                     4   Covariance Type:             nonrobust\n",
    "==============================================================================\n",
    "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "Intercept     -0.3055      0.070     -4.346      0.000      -0.443      -0.168\n",
    "arsenic        0.3791      0.039      9.840      0.000       0.304       0.455\n",
    "=============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coefficients in terms of odds\n",
    "\n",
    "# Load libraries and functions\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "import numpy as np\n",
    "\n",
    "# Fit logistic regression model\n",
    "model_GLM = glm(formula = 'switch ~ distance100',\n",
    "                data = wells,\n",
    "                family = sm.families.Binomial()).fit() \n",
    "\n",
    "# Extract model coefficients\n",
    "print('Model coefficients: \\n', model_GLM.params)\n",
    "\n",
    "# Compute odds\n",
    "print('Odds: \\n', np.exp(model_GLM.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rate of change in probability\n",
    "\n",
    "# Save distance100 from wells as x array\n",
    "x = 1.25\n",
    "\n",
    "# Extract intercept & slope from the fitted model\n",
    "intercept, slope = wells_GLM.params\n",
    "\n",
    "# Save distance100 from wells as x array\n",
    "x = 1.25\n",
    "\n",
    "# Compute and print the estimated probability\n",
    "est_prob = np.exp(intercept + slope*x)/(1+np.exp(intercept + slope*x))\n",
    "print('Estimated probability at x=1.25: ', round(est_prob,4))\n",
    "\n",
    "# Compute the slope of the tangent line for parameter beta at x\n",
    "slope_tan = slope * est_prob * (1 - est_prob)\n",
    "print('The rate of change in probability: ', round(slope_tan,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Statistical significance\n",
    "\n",
    "# Extract coefficients\n",
    "intercept, slope = crab_GLM.params\n",
    "\n",
    "# Estimated covariance matrix\n",
    "print(crab_GLM.cov_params())\n",
    "\n",
    "# Compute standard error (SE)\n",
    "std_error = np.sqrt(crab_GLM.cov_params().loc['width', 'width'])\n",
    "print('SE: ', round(std_error, 4))\n",
    "\n",
    "# Compute Wald statistic\n",
    "wald_stat = slope/std_error\n",
    "print('Wald statistic: ', round(wald_stat,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confidence intervals\n",
    "\n",
    "# Extract and print confidence intervals\n",
    "print(crab_GLM.conf_int())\n",
    "\n",
    "\n",
    "# Compute confidence intervals for the odds\n",
    "print(np.exp(crab_GLM.conf_int()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize model fit using regplot()\n",
    "\n",
    "# Plot distance and switch and add overlay with the logistic fit\n",
    "sns.regplot(x = 'arsenic', y = 'switch', \n",
    "            y_jitter = 0.03,\n",
    "            data = wells, \n",
    "            logistic = True,\n",
    "            ci = None)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute predictions\n",
    "\n",
    "# Compute predictions for the test sample wells_test and save as prediction\n",
    "prediction = wells_fit.predict(exog = wells_test)\n",
    "\n",
    "# Add computed predictions pred to the esixting data frame wells_test\n",
    "# and assign column name prediction\n",
    "wells_test['prediction'] = prediction\n",
    "\n",
    "# Examine the first 5 computed predictions\n",
    "print(wells_test[['switch', 'arsenic', 'prediction']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute confusion matrix\n",
    "\n",
    "# Compute class predictions y_pred\n",
    "y_prediction = np.where(prediction > cutoff, 1, 0)\n",
    "\n",
    "# Assign actual class labels from the test sample to y_actual\n",
    "y_actual = wells_test['switch']\n",
    "\n",
    "# Compute and print confusion matrix using crosstab function\n",
    "conf_mat = pd.crosstab(y_actual, y_prediction, \n",
    "                       rownames=['Actual'], \n",
    "                       colnames=['Predicted'], \n",
    "                       margins = True)\n",
    "                      \n",
    "# Print the confusion matrix\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODULE 3\n",
    "\n",
    "### Modeling Count Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here you'll learn about Poisson regression, including the discussion on count data, Poisson distribution and the interpretation of the model fit. You'll also learn how to overcome problems with overdispersion. Finally, you'll get hands-on experience with the process of model visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize the response\n",
    "\n",
    "# Import libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot sat variable\n",
    "sns.distplot(crab['sat'])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting a Poisson regression\n",
    "\n",
    "# Import libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "\n",
    "# Fit Poisson regression of sat by weight\n",
    "model = glm('sat ~ weight', data = crab, family = sm.families.Poisson()).fit()\n",
    "\n",
    "# Display model results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estimate parameter lambda\n",
    "\n",
    "# Import libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "\n",
    "# Fit Poisson regression of sat by width\n",
    "model = glm('sat ~ width', data = crab, family = sm.families.Poisson()).fit()\n",
    "\n",
    "# Display model results\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "## 2\n",
    "# Compute average crab width\n",
    "mean_width = np.mean(crab['width'])\n",
    "\n",
    "# Print the compute mean\n",
    "print('Average width: ', round(mean_width, 3))\n",
    "\n",
    "# Extract coefficients\n",
    "intercept, slope = model.params\n",
    "\n",
    "# Compute the estimated mean of y (lambda) at the average width\n",
    "est_lambda = np.exp(intercept) * np.exp(slope * mean_width)\n",
    "\n",
    "# Print estimated mean of y\n",
    "print('Estimated mean of y at average width: ', round(est_lambda, 3))\n",
    "\n",
    "# <script.py> output:\n",
    "#     Average width:  26.299\n",
    "#     Estimated mean of y at average width:  2.744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interpret Poisson coefficients\n",
    "\n",
    "model.summary()\n",
    "\n",
    "intercept, slope = model.params\n",
    "\n",
    "print(np.exp(slope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Poisson confidence intervals\n",
    "\n",
    "# Compute confidence intervals for the coefficients\n",
    "model_ci = model.conf_int()\n",
    "\n",
    "# Compute and print the confidence intervals for the multiplicative effect on the mean\n",
    "print(np.exp(model_ci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Is the mean equal to the variance?\n",
    "\n",
    "# Compute and print sample mean of the number of satellites. \n",
    "# Save as sat_mean\n",
    "sat_mean = np.mean(crab['sat'])\n",
    "print('Sample mean:', round(sat_mean, 3))\n",
    "\n",
    "# Compute and print sample variance of the number of satellites. \n",
    "# Save as sat_var\n",
    "sat_var = np.var(crab['sat'])\n",
    "print('Sample variance:', round(sat_var, 3))\n",
    "\n",
    "# Compute ratio of variance to mean\n",
    "print('Ratio:', round(sat_var/sat_mean, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing expected number of counts\n",
    "\n",
    "# Expected number of zero counts\n",
    "exp_zero_cnt = ((sat_mean**0)*np.exp(-sat_mean))/math.factorial(0)\n",
    "\n",
    "# Print exp_zero_counts\n",
    "print('Expected zero counts given mean of ', round(sat_mean,3), \n",
    "      'is ', round(exp_zero_cnt,3)*100)\n",
    "\n",
    "# Number of zero counts\n",
    "actual_zero_ant = sum(crab['y'] == 0)\n",
    "\n",
    "# Number of observations\n",
    "num_obs = len(crab)\n",
    "\n",
    "# Print the percentage of zero count observations in the sample\n",
    "print('Actual zero counts in the sample: ', round(actual_zero_ant / num_obs,3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking for overdispersion\n",
    "\n",
    "# Compute and print the overdispersion approximation\n",
    "print(crab_pois.pearson_chi2 / crab_pois.df_resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting negative binomial\n",
    "\n",
    "# Define the formula for the model fit\n",
    "formula = 'sat ~ width'\n",
    "\n",
    "# Fit the GLM negative binomial model using log link function\n",
    "crab_NB = smf.glm(formula = formula, data = crab, \n",
    "\t\t\t\t  family = sm.families.NegativeBinomial()).fit()\n",
    "\n",
    "# Print Poisson model's summary\n",
    "print(crab_pois.summary())\n",
    "\n",
    "# Print the negative binomial model's summary\n",
    "print(crab_NB.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confidence intervals for negative Binomial model\n",
    "\n",
    "# Compute confidence intervals for crab_Pois model\n",
    "print(crab_pois.conf_int())\n",
    "\n",
    "# Compute confidence intervals for crab_NB model\n",
    "print(crab_NB.conf_int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting data and linear model fit\n",
    "\n",
    "# Add fitted values to the fv column of crav dataframe\n",
    "crab['fit_values'] = crab.fit_values\n",
    "\n",
    "# Plot data points\n",
    "sns.regplot('width', 'sat', data = crab,\n",
    "            y_jitter = 0.3,\n",
    "            fit_reg = True, \n",
    "            line_kws = {'color':'green', \n",
    "                        'label':'LM fit'})\n",
    "\n",
    "# Poisson regression fitted values\n",
    "sns.scatterplot('width', 'fit_values', data = crab,\n",
    "           color = 'red', label = 'Poisson')\n",
    "           \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODULE 4\n",
    "\n",
    "## Multivariable Logistic Regression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this final chapter you'll learn how to increase the complexity of your model by adding more than one explanatory variable. You'll practice with the problem of multicollinearity, and with treating categorical and interaction terms in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit a multivariable logistic regression\n",
    "\n",
    "# Import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "\n",
    "# Define model formula\n",
    "formula = 'y ~ width + color'\n",
    "\n",
    "# Fit GLM\n",
    "model = glm(formula, data = crab, family = sm.families.Binomial()).fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The effect of multicollinearity\n",
    "\n",
    "# Import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "\n",
    "# Define model formula\n",
    "formula = 'y ~ width + weight'\n",
    "\n",
    "# Fit GLM\n",
    "model = glm(formula, data = crab, family = sm.families.Binomial()).fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute VIF\n",
    "\n",
    "# Import functions\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Get variables for which to compute VIF and add intercept term\n",
    "X = crab[['weight', 'width', 'color']]\n",
    "X['Intercept'] = 1\n",
    "\n",
    "# Compute and view VIF\n",
    "vif = pd.DataFrame()\n",
    "vif[\"variables\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# View results using print\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking model fit\n",
    "\n",
    "# Import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "\n",
    "# Define model formula\n",
    "formula = 'switch ~ distance100 + arsenic'\n",
    "\n",
    "# Fit GLM\n",
    "model_dist_ars = glm(formula, data = wells, family = sm.families.Binomial()).fit()\n",
    "\n",
    "# Compare deviance of null and residual model\n",
    "diff_deviance = model_dist_ars.null_deviance - model_dist_ars.deviance\n",
    "\n",
    "# Print the computed difference in deviance\n",
    "print(diff_deviance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare two models\n",
    "\n",
    "# Compute the difference in adding distance100 variable\n",
    "diff_deviance_distance = model_dist.null_deviance - model_dist.deviance\n",
    "\n",
    "# Print the computed difference in deviance\n",
    "print('Adding distance100 to the null model reduces deviance by: ', \n",
    "      round(diff_deviance_distance,3))\n",
    "\n",
    "# Compute the difference in adding arsenic variable\n",
    "diff_deviance_arsenic = model_dist.deviance - model_dist_ars.deviance\n",
    "\n",
    "# Print the computed difference in deviance\n",
    "print('Adding arsenic to the distance model reduced deviance further by: ', \n",
    "      round(diff_deviance_arsenic,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deviance and linear transformation\n",
    "\n",
    "# Import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "\n",
    "# Fit logistic regression model as save as model_1\n",
    "model_dist_1 = glm('switch ~ distance', data = wells, family = sm.families.Binomial()).fit()\n",
    "\n",
    "# Check the difference in deviance of model and model_1 \n",
    "print('Difference in deviance is: ', round(model_dist_1.deviance - model_dist.deviance,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model matrix for continuous variables\n",
    "\n",
    "# Import function dmatrix()\n",
    "from patsy import dmatrix\n",
    "\n",
    "# Construct model matrix with arsenic\n",
    "model_matrix = dmatrix('arsenic', data = wells, return_type = 'dataframe')\n",
    "print(model_matrix.head())\n",
    "\n",
    "# Import function dmatrix()\n",
    "from patsy import dmatrix\n",
    "\n",
    "# Construct model matrix with arsenic and distance100\n",
    "model_matrix = dmatrix('arsenic + distance100', data = wells, return_type = 'dataframe')\n",
    "print(model_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variable transformation\n",
    "\n",
    "# Import function dmatrix\n",
    "import numpy as np\n",
    "from patsy import dmatrix\n",
    "\n",
    "# Construct model matrix for arsenic with log transformation\n",
    "dmatrix('np.log(arsenic)', data = wells,\n",
    "       return_type = 'dataframe').head()\n",
    "\n",
    "\n",
    "# Import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "\n",
    "# Define model formula\n",
    "formula = 'switch ~ np.log(arsenic)'\n",
    "\n",
    "# Fit GLM\n",
    "model_log_ars = glm(formula=formula, data = wells, \n",
    "                     family = sm.families.Binomial()).fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model_log_ars.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coding categorical variables\n",
    "\n",
    "# Import function dmatrix\n",
    "from patsy import dmatrix\n",
    "\n",
    "# Construct model matrix for arsenic with log transformation\n",
    "print(dmatrix('C(color)', data = crab,\n",
    "     \t   return_type = 'dataframe').head())\n",
    "\n",
    "# Import function dmatrix\n",
    "from patsy import dmatrix\n",
    "\n",
    "# Construct model matrix for color with reference group 3\n",
    "print(dmatrix('C(color, Treatment(3))', \n",
    "     \t  data = crab,\n",
    "     \t  return_type = 'dataframe').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modeling with categorical variable\n",
    "\n",
    "# Construct model matrix\n",
    "model_matrix = dmatrix('C(color, Treatment(4))' , data = crab, \n",
    "                       return_type = 'dataframe')\n",
    "\n",
    "# Print first 5 rows of model matrix dataframe\n",
    "print(model_matrix.head())\n",
    "\n",
    "# Fit and results of a glm model with the above model matrix configuration\n",
    "model = glm('y ~ C(color, Treatment(4))', data = crab, \n",
    "            family = sm.families.Binomial()).fit()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "## 2 part\n",
    "# Construct model matrix\n",
    "model_matrix = dmatrix('C(color, Treatment(4)) + width', data = crab, return_type = 'dataframe')\n",
    "\n",
    "# Print first 5 rows of model matrix dataframe\n",
    "print(model_matrix.head())\n",
    "\n",
    "# Fit and results of a glm model with the above model matrix configuration\n",
    "model = glm('y ~ C(color, Treatment(4)) + width', data = crab, \n",
    "            family = sm.families.Binomial()).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interaction terms\n",
    "\n",
    "# Import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "\n",
    "# Fit GLM and print model summary\n",
    "model_int = glm('switch ~ center(distance100) + center(arsenic) + center(distance100):center(arsenic)', \n",
    "                data = wells, family = sm.families.Binomial()).fit()\n",
    "\n",
    "# View model results\n",
    "print(model_int.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
