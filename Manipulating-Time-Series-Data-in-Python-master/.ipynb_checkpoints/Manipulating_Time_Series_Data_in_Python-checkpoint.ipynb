{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Time Series in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your first time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Sunday\n",
      "0 Monday\n",
      "1 Tuesday\n",
      "2 Wednesday\n",
      "3 Thursday\n",
      "4 Friday\n",
      "5 Saturday\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavorodriguessilveira/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: `weekday_name` is deprecated and will be removed in a future version. Use `day_name` instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Create the range of dates here\n",
    "seven_days = pd.date_range('2017-1-1', periods = 7)\n",
    "\n",
    "# Iterate over the dates and print the number and name of the weekday\n",
    "for day in seven_days:\n",
    "    print(day.dayofweek, day.weekday_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('5_stocks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a time series of air quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4001 entries, 0 to 4000\n",
      "Data columns (total 6 columns):\n",
      "Date    4001 non-null object\n",
      "AAPL    4000 non-null float64\n",
      "AMZN    4000 non-null float64\n",
      "IBM     4000 non-null float64\n",
      "WMT     4000 non-null float64\n",
      "XOM     4000 non-null float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 187.6+ KB\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-77d353b260cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Convert the date column to datetime64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Set date column as index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "# Inspect data\n",
    "print(data.info())\n",
    "\n",
    "# Convert the date column to datetime64\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Set date column as index\n",
    "data = data.set_index('date')\n",
    "\n",
    "# Inspect data \n",
    "print(data.info())\n",
    "\n",
    "# Plot data\n",
    "data.plot(subplots = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare annual stock price trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'the label [2014] is not in the [index]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m                     \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1784\u001b[0m                                .format(key=key,\n\u001b[0;32m-> 1785\u001b[0;31m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the label [2014] is not in the [index]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-86cf8c58c12d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Select data for each year and concatenate with prices here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m'2014'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2015'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprice_per_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprice_per_year\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprice_per_year\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                 \u001b[0;31m# we have yielded a scalar ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1796\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m                 \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 raise KeyError(u\"the label [{key}] is not in the [{axis}]\"\n\u001b[1;32m   1784\u001b[0m                                .format(key=key,\n\u001b[0;32m-> 1785\u001b[0;31m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the label [2014] is not in the [index]'"
     ]
    }
   ],
   "source": [
    "# Create dataframe prices here\n",
    "prices = pd.DataFrame()\n",
    "\n",
    "# Select data for each year and concatenate with prices here \n",
    "for year in ['2013', '2014', '2015']:\n",
    "    price_per_year = prices.loc[year, ['price']].reset_index(drop=True)\n",
    "    price_per_year.rename(columns={'price': year}, inplace=True)\n",
    "    prices = pd.concat([prices, price_per_year], axis=1)\n",
    "\n",
    "# Plot prices\n",
    "prices.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set and change time series frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data\n",
    "print(co.info())\n",
    "\n",
    "# Set the frequency to calendar daily\n",
    "co = co.asfreq('D')\n",
    "\n",
    "# Plot the data\n",
    "co.plot(subplots = True)\n",
    "plt.show()\n",
    "\n",
    "# Set frequency to monthly\n",
    "co = co.asfreq('M')\n",
    "\n",
    "# Plot the data\n",
    "co.plot(subplots = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting stock prices across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "google = pd.read_csv('google.csv', parse_dates = ['Date'], index_col = 'Date')\n",
    "\n",
    "# Set data frequency to business daily\n",
    "google = google.asfreq('B')\n",
    "\n",
    "# Create 'lagged' and 'shifted'\n",
    "google['lagged'] = google['Close'].shift(periods = -90)\n",
    "google['shifted'] = google['Close'].shift(periods = 90)\n",
    "\n",
    "# Plot the google price series\n",
    "google.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating stock price changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created shifted_30 here\n",
    "yahoo['shifted_30'] = yahoo.shift(periods = 30)\n",
    "\n",
    "# Subtract shifted_30 from price\n",
    "yahoo['change_30'] = yahoo['price']-yahoo['shifted_30'] \n",
    "\n",
    "# Get the 30-day price difference\n",
    "yahoo['diff_30'] = yahoo['price'].diff(periods = 30)\n",
    "\n",
    "# Inspect the last five rows of price\n",
    "print(yahoo.tail())\n",
    "\n",
    "# Show the value_counts of the difference between change_30 and diff_30\n",
    "print(yahoo.change_30.sub(yahoo['diff_30']).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting multi-period returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create daily_return\n",
    "google['daily_return'] = google.Close.pct_change().mul(100)\n",
    "\n",
    "# Create monthly_return\n",
    "google['monthly_return'] = google.Close.pct_change(30).mul(100)\n",
    "\n",
    "# Create annual_return\n",
    "google['annual_return'] = google.Close.pct_change(360).mul(100)\n",
    "\n",
    "# Plot the result\n",
    "google.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Time Series Metrics & Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the performance of several asset classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "prices = pd.read_csv('asset_classes.csv', parse_dates = ['DATE'], index_col = 'DATE')\n",
    "\n",
    "# Inspect prices here\n",
    "print(prices.info())\n",
    "\n",
    "# Select first prices\n",
    "first_prices = prices.iloc[0]\n",
    "\n",
    "# Create normalized\n",
    "normalized = prices.div(first_prices).mul(100)\n",
    "\n",
    "# Plot normalized\n",
    "normalized.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing stock prices with a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stock prices and index here\n",
    "stocks = pd.read_csv('nyse.csv', parse_dates = ['date'], index_col = 'date')\n",
    "dow_jones = pd.read_csv('dow_jones.csv', parse_dates = ['date'], index_col = 'date')\n",
    "\n",
    "# Concatenate data and inspect result here\n",
    "data = pd.concat([stocks, dow_jones], axis = 1)\n",
    "print(data.info())\n",
    "\n",
    "# Normalize and plot your data here\n",
    "data.div(data.iloc[0]).mul(100).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot performance difference vs benchmark index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tickers\n",
    "tickers = ['MSFT', 'AAPL']\n",
    "\n",
    "# Import stock data here\n",
    "stocks = pd.read_csv('msft_aapl.csv', parse_dates = ['date'], index_col = 'date')\n",
    "\n",
    "# Import index here\n",
    "sp500 = pd.read_csv('sp500.csv', parse_dates = ['date'], index_col = 'date')\n",
    "\n",
    "# Concatenate stocks and index here\n",
    "data = pd.concat([stocks, sp500], axis = 1).dropna()\n",
    "\n",
    "# Normalize data\n",
    "normalized = data.div(data.iloc[0]).mul(100)\n",
    "\n",
    "# Subtract the normalized index from the normalized stock prices, and plot the result\n",
    "normalized[tickers].sub(normalized['SP500'], axis = 0).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert monthly to weekly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start and end dates\n",
    "start = '2016-1-1'\n",
    "end = '2016-2-29'\n",
    "\n",
    "# Create monthly_dates here\n",
    "monthly_dates = pd.date_range(start=start, end=end, freq='M')\n",
    "\n",
    "# Create monthly here\n",
    "monthly = pd.Series(data=[1,2], index=monthly_dates)\n",
    "print(monthly)\n",
    "\n",
    "# Create weekly_dates here\n",
    "weekly_dates = pd.date_range(start=start, end=end, freq='W')\n",
    "\n",
    "# Print monthly, reindexed using weekly_dates\n",
    "print(monthly.reindex(weekly_dates))\n",
    "print(monthly.reindex(weekly_dates, method='bfill'))\n",
    "print(monthly.reindex(weekly_dates, method='ffill'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create weekly from monthly unemployment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "data = pd.read_csv('unemployment.csv', parse_dates = ['date'], index_col = 'date')\n",
    "\n",
    "# Show first five rows of weekly series\n",
    "print(data.asfreq('W').head())\n",
    "\n",
    "# Show first five rows of weekly series with bfill option\n",
    "print(data.asfreq('W', method = 'bfill').head())\n",
    "\n",
    "# Create weekly series with ffill option and show first five rows\n",
    "weekly_ffill = data.asfreq('W', method = 'ffill')\n",
    "print(weekly_ffill.head())\n",
    "\n",
    "# Plot weekly_fill starting 2015 here \n",
    "weekly_ffill['2015':].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use interpolation to create weekly employment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data here\n",
    "print(monthly.info())\n",
    "\n",
    "# Create weekly dates\n",
    "weekly_dates = pd.date_range(start = monthly.index.min(), end = monthly.index.max(), freq = 'W')\n",
    "\n",
    "# Reindex monthly to weekly data\n",
    "weekly = monthly.reindex(weekly_dates)\n",
    "\n",
    "# Create ffill and interpolated columns\n",
    "weekly['ffill'] = weekly.UNRATE.ffill()\n",
    "weekly['interpolated'] = weekly.UNRATE.interpolate()\n",
    "\n",
    "# Plot weekly\n",
    "weekly.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate debt/GDP and compare to unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import & inspect data here\n",
    "data = pd.read_csv('debt_unemployment.csv', parse_dates = ['date'], index_col = 'date')\n",
    "print(data.info())\n",
    "\n",
    "# Interpolate and inspect here\n",
    "interpolated = data.interpolate()\n",
    "print(interpolated.info())\n",
    "\n",
    "# Plot interpolated data here\n",
    "interpolated.plot(secondary_y = 'Unemployment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare weekly, monthly and annual ozone trends for NYC & LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect data here\n",
    "ozone = pd.read_csv('ozone.csv', parse_dates = ['date'], index_col = 'date')\n",
    "print(ozone.info())\n",
    "\n",
    "# Calculate and plot the weekly average ozone trend\n",
    "ozone.resample('W').mean().plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate and plot the monthly average ozone trend\n",
    "ozone.resample('M').mean().plot()\n",
    "plt.show()\n",
    "# Calculate and plot the annual average ozone trend\n",
    "ozone.resample('A').mean().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare monthly average stock prices for Facebook and Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect data here\n",
    "stocks = pd.read_csv('stocks.csv', parse_dates = ['date'], index_col = 'date')\n",
    "print(stocks.info())\n",
    "\n",
    "# Calculate and plot the monthly averages\n",
    "monthly_average = stocks.resample('M').mean()\n",
    "monthly_average.plot(subplots = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare quarterly GDP growth rate and stock returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect gdp_growth here\n",
    "gdp_growth = pd.read_csv('gdp_growth.csv', parse_dates=['date'], index_col='date')\n",
    "gdp_growth.info()\n",
    "\n",
    "# Import and inspect djia here\n",
    "djia = pd.read_csv('djia.csv', parse_dates=['date'], index_col='date')\n",
    "djia.info()\n",
    "\n",
    "# Calculate djia quarterly returns here \n",
    "djia_quarterly = djia.resample('QS').first()\n",
    "djia_quarterly_return = djia_quarterly.pct_change().mul(100)\n",
    "\n",
    "# Concatenate, rename and plot djia_quarterly_return and gdp_growth here \n",
    "data = pd.concat([gdp_growth, djia_quarterly_return], axis=1)\n",
    "data.columns = ['gdp', 'djia']\n",
    "\n",
    "data.plot()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize monthly mean, median and standard deviation of S&P500 returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "sp500 = pd.read_csv('sp500.csv', parse_dates = ['date'], index_col = 'date')\n",
    "print(sp500.info())\n",
    "\n",
    "# Calculate daily returns here\n",
    "daily_returns = sp500.squeeze().pct_change()\n",
    "\n",
    "# Resample and calculate statistics\n",
    "stats = daily_returns.resample('M').agg(['mean', 'median', 'std'])\n",
    "\n",
    "# Plot stats here\n",
    "stats.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window Functions: Rolling & Expanding Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling average air quality since 2010 for new york city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect ozone data here\n",
    "data = pd.read_csv('ozone.csv', parse_dates=['date'], index_col='date')\n",
    "print(data.info())\n",
    "\n",
    "# Calculate 90d and 360d rolling mean\n",
    "data['90D'] = data.Ozone.rolling('90D').mean()\n",
    "data['360D'] = data.Ozone.rolling('360D').mean()\n",
    "\n",
    "# Plot data\n",
    "data['2010':].plot(title='New York City')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling 360-day median & std. deviation for nyc ozone data since 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect ozone data here\n",
    "data = pd.read_csv('ozone.csv', parse_dates = ['date'], index_col = 'date').dropna()\n",
    "\n",
    "# Calculate the rolling mean and std here\n",
    "rolling_stats = data.Ozone.rolling(360).agg(['mean', 'std'])\n",
    "\n",
    "# Join rolling_stats with ozone data\n",
    "stats = pd.concat([data, rolling_stats], axis = 1)\n",
    "\n",
    "# Plot stats\n",
    "stats.plot(subplots = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling quantiles for daily air quality in nyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample, interpolate and inspect ozone data here\n",
    "data = data.resample('D').interpolate()\n",
    "data.info()\n",
    "\n",
    "# Create the rolling window\n",
    "rolling = data.rolling(360)['Ozone']\n",
    "\n",
    "# Insert the rolling quantiles to the monthly returns\n",
    "data['q10'] = rolling.quantile(.1)\n",
    "data['q50'] = rolling.quantile(.5)\n",
    "data['q90'] = rolling.quantile(.9)\n",
    "\n",
    "# Plot the data\n",
    "data.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative sum vs .diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate differences\n",
    "differences = data.diff().dropna()\n",
    "\n",
    "# Select start price\n",
    "start_price = data.first('D')\n",
    "\n",
    "# Calculate cumulative sum\n",
    "cumulative_sum = start_price.append(differences).cumsum()\n",
    "\n",
    "# Validate cumulative sum equals data\n",
    "print(data.equals(cumulative_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative return on $1,000 invested in google vs apple I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your investment\n",
    "investment = 1000\n",
    "\n",
    "# Calculate the daily returns here\n",
    "returns = data.pct_change()\n",
    "\n",
    "# Calculate the cumulative returns here\n",
    "returns_plus_one = returns + 1\n",
    "cumulative_return = returns_plus_one.cumprod()\n",
    "\n",
    "# Calculate and plot the investment return here \n",
    "cumulative_return.mul(investment).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative return on $1,000 invested in google vs apple II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Define a multi_period_return function\n",
    "def multi_period_return(period_returns):\n",
    "    return np.prod(period_returns + 1) - 1\n",
    "    \n",
    "# Calculate daily returns\n",
    "daily_returns = data.pct_change()\n",
    "\n",
    "# Calculate rolling_annual_returns\n",
    "rolling_annual_returns = daily_returns.rolling('360D').apply(multi_period_return)\n",
    "\n",
    "# Plot rolling_annual_returns\n",
    "rolling_annual_returns.mul(100).plot();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random walk I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed here\n",
    "seed = 42\n",
    "\n",
    "# Create random_walk\n",
    "random_walk = normal(size =2500, loc = 0.001, scale = 0.01)\n",
    "\n",
    "# Convert random_walk to pd.series\n",
    "random_walk = pd.Series(random_walk)\n",
    "\n",
    "# Create random_prices\n",
    "random_prices = (random_walk + 1).cumprod()\n",
    "\n",
    "# Plot random_prices here\n",
    "random_prices.mul(1000)[1000:].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random walk II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed here\n",
    "seed = 42\n",
    "\n",
    "# Calculate daily_returns here\n",
    "daily_returns = fb.pct_change().dropna()\n",
    "\n",
    "# Get n_obs\n",
    "n_obs = daily_returns.count()\n",
    "\n",
    "# Create random_walk\n",
    "random_walk = choice(daily_returns, size = n_obs)\n",
    "\n",
    "# Convert random_walk to pd.series\n",
    "random_walk = pd.Series(random_walk)\n",
    "\n",
    "# Plot random_walk distribution\n",
    "sns.distplot(random_walk)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random walk III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select fb start price here\n",
    "start = fb.price.first('D')\n",
    "\n",
    "# Add 1 to random walk and append to start\n",
    "random_walk = random_walk +1\n",
    "random_price = start.append(random_walk)\n",
    "\n",
    "# Calculate cumulative product here\n",
    "random_price = random_price.cumprod()\n",
    "\n",
    "# Insert into fb and plot\n",
    "fb['random'] = random_price\n",
    "fb.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual return correlations among several stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data here\n",
    "print(data.info())\n",
    "\n",
    "# Calculate year-end prices here\n",
    "annual_prices = data.resample('A').last()\n",
    "\n",
    "# Calculate annual returns here\n",
    "annual_returns = annual_prices.pct_change()\n",
    "\n",
    "# Calculate and print the correlation matrix here\n",
    "correlations = annual_returns.corr()\n",
    "print(correlations)\n",
    "\n",
    "# Visualize the correlations as heatmap here\n",
    "sns.heatmap(correlations, annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together: Building a value-weighted index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore and clean company listing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect listings\n",
    "print(listings.info())\n",
    "\n",
    "# Move 'stock symbol' into the index\n",
    "listings.set_index('Stock Symbol', inplace = True)\n",
    "\n",
    "# Drop rows with missing 'sector' data\n",
    "listings = listings.dropna(subset = ['Sector'])\n",
    "\n",
    "# Select companies with IPO Year before 2019\n",
    "listings = listings[listings['IPO Year'] < 2019]\n",
    "\n",
    "# Inspect the new listings data\n",
    "print(listings.info())\n",
    "\n",
    "# Show the number of companies per sector\n",
    "print(listings.groupby('Sector').size().sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and inspect index components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select largest company for each sector\n",
    "components = listings.groupby('Sector')['Market Capitalization'].nlargest(1)\n",
    "\n",
    "# Print components, sorted by market cap\n",
    "print(components.sort_values(ascending = False))\n",
    "\n",
    "# Select stock symbols and print the result\n",
    "tickers = components.index.get_level_values(1)\n",
    "print(tickers)\n",
    "\n",
    "# Print company name, market cap, and last price for each component \n",
    "info_cols = ['Company Name', 'Market Capitalization', 'Last Sale']\n",
    "print(listings.loc[tickers, info_cols].sort_values('Market Capitalization', ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import index component price information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tickers\n",
    "print(tickers)\n",
    "\n",
    "# Import prices and inspect result\n",
    "stock_prices = pd.read_csv('stock_prices.csv', parse_dates = ['Date'], index_col = 'Date')\n",
    "print(stock_prices.info())\n",
    "\n",
    "# Calculate the returns    \n",
    "price_return = (stock_prices.iloc[-1].div(stock_prices.iloc[0]).sub(1)).mul(100)\n",
    "\n",
    "# Plot horizontal bar chart of sorted price_return   \n",
    "price_return.sort_values().plot(kind = 'barh', title = 'Stock Price Returns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate number of shares outstanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect listings and print tickers\n",
    "print(listings.info())\n",
    "print(tickers)\n",
    "\n",
    "# Select components and relevant columns from listings\n",
    "components = listings.loc[tickers, ['Market Capitalization','Last Sale']]\n",
    "\n",
    "# Print the first rows of components\n",
    "print(components.head())\n",
    "\n",
    "# Calculate the number of shares here\n",
    "no_shares = components['Market Capitalization'].div(components['Last Sale'])\n",
    "\n",
    "# Print the sorted no_shares\n",
    "print(no_shares.sort_values(ascending = False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create time series of market value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the number of shares\n",
    "no_shares = components['Number of Shares']\n",
    "print(no_shares.sort_values())\n",
    "\n",
    "# Create the series of market cap per ticker\n",
    "market_cap = stock_prices.mul(no_shares)\n",
    "\n",
    "# Select first and last market cap here\n",
    "first_value = market_cap.iloc[0]\n",
    "last_value = market_cap.iloc[-1]\n",
    "\n",
    "# Concatenate and plot first and last market cap here\n",
    "pd.concat([first_value, last_value], axis = 1).plot(kind = 'barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate & plot the composite index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate and print the market cap per trading day\n",
    "raw_index = market_cap_series.sum(axis = 1)\n",
    "print(raw_index)\n",
    "\n",
    "# Normalize the aggregate market cap here \n",
    "index = raw_index.div(raw_index.iloc[0]).mul(100)\n",
    "print(index)\n",
    "\n",
    "# Plot the index here\n",
    "index.plot(title = 'Market-Cap Weighted Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the contribution of each stock to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the index return here\n",
    "index_return = (index.iloc[-1]/index.iloc[0] - 1) * 100\n",
    "print(index_return)\n",
    "\n",
    "# Select the market capitalization\n",
    "market_cap = components['Market Capitalization']\n",
    "\n",
    "# Calculate the total market cap\n",
    "total_market_cap = market_cap.sum()\n",
    "\n",
    "# Calculate the component weights, and print the result\n",
    "weights = market_cap.div(total_market_cap)\n",
    "print(weights.sort_values())\n",
    "\n",
    "# Calculate and plot the contribution by component\n",
    "weights.mul(index_return).sort_values().plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare index performance against benchmark I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index series to dataframe here\n",
    "data = index.to_frame('Index')\n",
    "\n",
    "# Normalize djia series and add as new column to data\n",
    "djia = djia.div(djia.iloc[0]).mul(100)\n",
    "data['DJIA'] = djia\n",
    "\n",
    "# Show total return for both index and djia\n",
    "print(((data.iloc[-1]/data.iloc[0]) -1)*100)\n",
    "\n",
    "# Plot both series\n",
    "data.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare index performance against benchmark II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data\n",
    "print(data.info())\n",
    "print(data.head())\n",
    "\n",
    "# Create multi_period_return function here\n",
    "def multi_period_return(r):\n",
    "    return (np.prod(r+1)-1) * 100\n",
    "\n",
    "# Calculate rolling_return_360\n",
    "rolling_return_360 = data.pct_change().rolling('360D').apply(multi_period_return)\n",
    "\n",
    "# Plot rolling_return_360 here\n",
    "rolling_return_360.plot(title = 'Rolling 360D Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize your index constituent correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect stock_prices here\n",
    "print(stock_prices.info())\n",
    "\n",
    "# Calculate the daily returns\n",
    "returns = stock_prices.pct_change()\n",
    "\n",
    "# Calculate and print the pairwise correlations\n",
    "correlations = returns.corr()\n",
    "print(correlations)\n",
    "\n",
    "# Plot a heatmap of daily return correlations\n",
    "sns.heatmap(correlations, annot = True)\n",
    "plt.title('Daily Return Correlations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your analysis to multiple excel worksheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect index and stock_prices\n",
    "print(index.info())\n",
    "print(stock_prices.info())\n",
    "\n",
    "# Join index to stock_prices, and inspect the result\n",
    "data = stock_prices.join(index)\n",
    "print(data.info())\n",
    "\n",
    "# Create index & stock price returns\n",
    "returns = data.pct_change()\n",
    "\n",
    "# export data and data as returns to excel\n",
    "with pd.ExcelWriter('data.xls') as writer:\n",
    "    data.to_excel(writer, sheet_name='data')\n",
    "    returns.to_excel(writer, sheet_name='returns')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
